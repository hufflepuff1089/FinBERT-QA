{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "process-bert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDRK9Ogoh8Xn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# collection = pd.read_csv(path+\"data-bert/collection_new.tsv\", sep=\"\\t\", header=None)\n",
        "# collection = collection.rename(columns={0: 'docid', 1: 'doc'})\n",
        "\n",
        "# def load_questions(path):\n",
        "#     \"\"\"\n",
        "#     Returns a dataframe of cols: qid, question\n",
        "#     \"\"\"\n",
        "#     # Question ID and Question text\n",
        "#     query_df = pd.read_csv(path, sep=\"\\t\")\n",
        "#     queries = query_df[['qid', 'question']]\n",
        "\n",
        "#     return queries\n",
        "\n",
        "# queries = load_questions(path + \"FiQA_train_question_final.tsv\")\n",
        "\n",
        "# queries['tokenized_q'] = queries['question'].apply(lambda x: tokenizer.tokenize(x))\n",
        "# queries['len'] = queries['tokenized_q'].apply(lambda x: len(x))\n",
        "\n",
        "# collection['tokenized_a'] = collection['doc'].apply(lambda x: tokenizer.tokenize(x))\n",
        "# collection['len'] = collection['tokenized_a'].apply(lambda x: len(x))\n",
        "\n",
        "# label_to_ans = {}\n",
        "\n",
        "# for index, row in collection.iterrows():\n",
        "#     label_to_ans[row['docid']] = row['tokenized_a']\n",
        "\n",
        "# # Question to question text\n",
        "# qid_to_text = {}\n",
        "\n",
        "# for index, row in queries.iterrows():\n",
        "#     qid_to_text[row['qid']] = row['tokenized_q']\n",
        "\n",
        "# # save_pickle(path+\"data-bert/label_to_ans.pickle\", label_to_ans)\n",
        "# # save_pickle(path+\"data-bert/qid_to_text.pickle\", qid_to_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNH19aXWh_5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"Max answer len: {}\".format(collection['len'].max()))\n",
        "# print(\"Min answer len: {}\".format(collection['len'].min()))\n",
        "# print(\"Average answer len: {}\".format(collection['len'].mean()))\n",
        "\n",
        "# print(\"Max question len: {}\".format(queries['len'].max()))\n",
        "# print(\"Min question len: {}\".format(queries['len'].min()))\n",
        "# print(\"Average question len: {}\".format(queries['len'].mean()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viA1zoR0x-Xw",
        "colab_type": "text"
      },
      "source": [
        "test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjU1FJCJiCnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for row in test_set:\n",
        "#     row[2] = [x for x in row[2] if x not in row[1]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSYn4BXpyAOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_df = pd.DataFrame(test_set)\n",
        "# test_df = test_df.rename(columns={0: 'qid', 1: 'pos', 2:'cand'})\n",
        "# # test_df = test_df[['qid', 'cand']]\n",
        "\n",
        "# test_df.head(5)\n",
        "\n",
        "# test_pos = test_df[['qid', 'pos']]\n",
        "# test_pos = test_pos.explode('pos')\n",
        "# test_pos = test_pos.rename(columns={'pos': 'docid'})\n",
        "# test_pos['label'] = test_pos.apply(lambda x: 1, axis=1)\n",
        "\n",
        "# len(test_pos)\n",
        "\n",
        "# test_neg = test_df[['qid', 'cand']]\n",
        "# test_neg = test_neg.explode('cand')\n",
        "# test_neg = test_neg.rename(columns={'cand': 'docid'})\n",
        "# test_neg ['label'] = test_neg .apply(lambda x: 0, axis=1)\n",
        "\n",
        "# test_neg.head(5)\n",
        "\n",
        "# test_data = pd.concat([test_pos, test_neg]).sort_values(by=['qid'])\n",
        "\n",
        "# test_data['question'] = test_data['qid'].apply(lambda x: qid_to_text[x])\n",
        "# test_data['ans_cand'] = test_data['docid'].apply(lambda x: label_to_ans[x])\n",
        "# test_data['ques_token'] = test_data['question'].apply(lambda x: add_question_token(x))\n",
        "# test_data['ans_cand'] = test_data['ans_cand'].apply(lambda x: add_ans_token(x))\n",
        "\n",
        "# test_data = test_data[['qid', 'docid', 'label', 'ans_cand','ques_token']]\n",
        "# test_data['seq'] = test_data['ques_token'] + test_data['ans_cand']\n",
        "# test_data['seq_clipped'] = test_data['seq'].apply(clip)\n",
        "\n",
        "# test_data.head(5)\n",
        "\n",
        "# docid_map = test_data[['docid', 'seq_clipped']]\n",
        "# test_docid_to_seq = {}\n",
        "\n",
        "# for index, row in docid_map.iterrows():\n",
        "#     test_docid_to_seq[row['docid']] = row['seq_clipped']\n",
        "\n",
        "# print(take(5, test_docid_to_seq.items()))\n",
        "\n",
        "# save_pickle(path+'data-bert/test_docid_to_seq.pickle', test_docid_to_seq)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}