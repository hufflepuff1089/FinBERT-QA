{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bertQA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySXHdHsEUxNd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6bd3c14e-6763-45a1-83c1-986476a694a3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"drive/My Drive/FiQA/\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbIIxiVhU1VL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from itertools import islice\n",
        "\n",
        "def take(n, iterable):\n",
        "    \"Return first n items of the iterable as a list\"\n",
        "    return list(islice(iterable, n))\n",
        "\n",
        "def remove_empty(test_set):\n",
        "    for index, row in enumerate(test_set):\n",
        "        for doc in row[1]:\n",
        "            if doc in empty_docs:\n",
        "                del test_set[index]\n",
        "    return test_set\n",
        "\n",
        "def load_pickle(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "def save_pickle(path, data):\n",
        "    with open(path, 'wb') as handle:\n",
        "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZbiuVLWVN9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set = load_pickle(path + 'data-bert/data_train_50.pickle')\n",
        "empty_docs = load_pickle(path+'empty_docs.pickle')\n",
        "train_set = [x for x in train_set if x[1] not in empty_docs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6npVgMDNewIW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "46952904-61b4-4fb3-aa6d-5d6fd15d606a"
      },
      "source": [
        "!pip install transformers\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.11)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.10)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.10 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.10->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.10->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpLr8nlabAAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "collection = pd.read_csv(path+\"data-bert/collection_new.tsv\", sep=\"\\t\", header=None)\n",
        "collection = collection.rename(columns={0: 'docid', 1: 'doc'})\n",
        "\n",
        "def load_questions(path):\n",
        "    \"\"\"\n",
        "    Returns a dataframe of cols: qid, question\n",
        "    \"\"\"\n",
        "    # Question ID and Question text\n",
        "    query_df = pd.read_csv(path, sep=\"\\t\")\n",
        "    queries = query_df[['qid', 'question']]\n",
        "\n",
        "    return queries\n",
        "\n",
        "queries = load_questions(path + \"FiQA_train_question_final.tsv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX3FzGfQqVY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "queries['tokenized_q'] = queries['question'].apply(lambda x: tokenizer.tokenize(x))\n",
        "queries['len'] = queries['tokenized_q'].apply(lambda x: len(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj3D1_Xnq1fr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c016ca5c-e885-4ae1-de43-112310d2ffce"
      },
      "source": [
        "queries.len.max()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnAKnFyyshH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "collection['tokenized_a'] = collection['doc'].apply(lambda x: tokenizer.tokenize(x))\n",
        "collection['len'] = collection['tokenized_a'].apply(lambda x: len(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxifPmTesv1P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "3f9e2e9c-0d17-43a0-ee4a-f31fd4dfae64"
      },
      "source": [
        "collection.head(5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docid</th>\n",
              "      <th>doc</th>\n",
              "      <th>tokenized_a</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>I'm not saying I don't like the idea of on-the...</td>\n",
              "      <td>[i, ', m, not, saying, i, don, ', t, like, the...</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31</td>\n",
              "      <td>So nothing preventing false ratings besides ad...</td>\n",
              "      <td>[so, nothing, preventing, false, ratings, besi...</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56</td>\n",
              "      <td>You can never use a health FSA for individual ...</td>\n",
              "      <td>[you, can, never, use, a, health, f, ##sa, for...</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>59</td>\n",
              "      <td>Samsung created the LCD and other flat screen ...</td>\n",
              "      <td>[samsung, created, the, lcd, and, other, flat,...</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>63</td>\n",
              "      <td>Here are the SEC requirements: The federal sec...</td>\n",
              "      <td>[here, are, the, sec, requirements, :, the, fe...</td>\n",
              "      <td>254</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   docid  ...  len\n",
              "0      3  ...  100\n",
              "1     31  ...   95\n",
              "2     56  ...  100\n",
              "3     59  ...   62\n",
              "4     63  ...  254\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEFfAeIbv-60",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "b55e799f-37df-4999-c5b4-1a905b316837"
      },
      "source": [
        "queries.head(5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question</th>\n",
              "      <th>tokenized_q</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>What is considered a business expense on a bus...</td>\n",
              "      <td>[what, is, considered, a, business, expense, o...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Claiming business expenses for a business with...</td>\n",
              "      <td>[claiming, business, expenses, for, a, busines...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Transferring money from One business checking ...</td>\n",
              "      <td>[transferring, money, from, one, business, che...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Having a separate bank account for business/in...</td>\n",
              "      <td>[having, a, separate, bank, account, for, busi...</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Business Expense - Car Insurance Deductible Fo...</td>\n",
              "      <td>[business, expense, -, car, insurance, de, ##d...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   qid  ... len\n",
              "0    0  ...  11\n",
              "1    1  ...   9\n",
              "2    2  ...  10\n",
              "3    3  ...  18\n",
              "4    4  ...  17\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMG9ijhNaUj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_to_ans = {}\n",
        "\n",
        "for index, row in collection.iterrows():\n",
        "    label_to_ans[row['docid']] = row['tokenized_a']\n",
        "\n",
        "# Question to question text\n",
        "qid_to_text = {}\n",
        "\n",
        "for index, row in queries.iterrows():\n",
        "    qid_to_text[row['qid']] = row['tokenized_q']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXwjgq4zuPzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_pickle(path+\"data-bert/label_to_ans.pickle\", label_to_ans)\n",
        "save_pickle(path+\"data-bert/qid_to_text.pickle\", qid_to_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZERfpbehdwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_question_token(q_tokens):\n",
        "    c = \"[CLS]\"\n",
        "    s = \"[SEP]\"\n",
        "    q_tokens = [c] + q_tokens\n",
        "    q_tokens = q_tokens + [s]\n",
        "\n",
        "    return q_tokens\n",
        "\n",
        "def add_ans_token(a_tokens):\n",
        "    s = \"[SEP]\"\n",
        "    a_tokens = a_tokens + [s]\n",
        "\n",
        "    return a_tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcnub5RAVxJD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "48bf5f17-4383-415f-9bfb-cc5b5d44eb28"
      },
      "source": [
        "train_df = pd.DataFrame(train_set)\n",
        "\n",
        "train_df = train_df.rename(columns={0: 'qid', 1: 'pos', 2:'neg'})\n",
        "\n",
        "train_pos = train_df[['qid', 'pos']]\n",
        "train_pos = train_pos.rename(columns={'pos': 'docid'})\n",
        "train_pos['label'] = train_pos.apply(lambda x: 1, axis=1)\n",
        "train_pos = train_pos.drop_duplicates()\n",
        "\n",
        "train_neg = train_df[['qid', 'neg']]\n",
        "train_neg = train_neg.rename(columns={'neg': 'docid'})\n",
        "train_neg['label'] = train_neg.apply(lambda x: 0, axis=1)\n",
        "\n",
        "train = pd.concat([train_pos, train_neg]).sort_values(by=['qid'])\n",
        "\n",
        "train.head(5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>docid</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>18850</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>408058</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>343708</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>311069</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>139094</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    qid   docid  label\n",
              "0     0   18850      1\n",
              "20    0  408058      0\n",
              "21    0  343708      0\n",
              "22    0  311069      0\n",
              "23    0  139094      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1FJJSYYdAXq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "645a5698-49da-450b-bd7c-12927558a64a"
      },
      "source": [
        "train['question'] = train['qid'].apply(lambda x: qid_to_text[x])\n",
        "train['ans_cand'] = train['docid'].apply(lambda x: label_to_ans[x])\n",
        "train['ques_token'] = train['question'].apply(lambda x: add_question_token(x))\n",
        "train['ans_cand'] = train['ans_cand'].apply(lambda x: add_ans_token(x))\n",
        "\n",
        "# train['seq'] = train[['question', 'ans_cand']].apply(lambda x: ' '.join(x), axis=1)\n",
        "\n",
        "train.head(5)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>docid</th>\n",
              "      <th>label</th>\n",
              "      <th>question</th>\n",
              "      <th>ans_cand</th>\n",
              "      <th>ques_token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>18850</td>\n",
              "      <td>1</td>\n",
              "      <td>[what, is, considered, a, business, expense, o...</td>\n",
              "      <td>[the, irs, guidance, pertaining, to, the, subj...</td>\n",
              "      <td>[[CLS], what, is, considered, a, business, exp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>408058</td>\n",
              "      <td>0</td>\n",
              "      <td>[what, is, considered, a, business, expense, o...</td>\n",
              "      <td>[the, advice, you, were, given, in, the, other...</td>\n",
              "      <td>[[CLS], what, is, considered, a, business, exp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>343708</td>\n",
              "      <td>0</td>\n",
              "      <td>[what, is, considered, a, business, expense, o...</td>\n",
              "      <td>[the, us, with, ##holding, tax, applies, to, s...</td>\n",
              "      <td>[[CLS], what, is, considered, a, business, exp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>311069</td>\n",
              "      <td>0</td>\n",
              "      <td>[what, is, considered, a, business, expense, o...</td>\n",
              "      <td>[&amp;, gt, ;, you, also, have, to, think, about, ...</td>\n",
              "      <td>[[CLS], what, is, considered, a, business, exp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>139094</td>\n",
              "      <td>0</td>\n",
              "      <td>[what, is, considered, a, business, expense, o...</td>\n",
              "      <td>[they, are, similar, in, the, sense, that, the...</td>\n",
              "      <td>[[CLS], what, is, considered, a, business, exp...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    qid  ...                                         ques_token\n",
              "0     0  ...  [[CLS], what, is, considered, a, business, exp...\n",
              "20    0  ...  [[CLS], what, is, considered, a, business, exp...\n",
              "21    0  ...  [[CLS], what, is, considered, a, business, exp...\n",
              "22    0  ...  [[CLS], what, is, considered, a, business, exp...\n",
              "23    0  ...  [[CLS], what, is, considered, a, business, exp...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsdFC_JBxQX-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "0a5d45e5-c500-478c-e029-70ec29e1d91b"
      },
      "source": [
        "train.at[0, \"ques_token\"]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list(['[CLS]', 'what', 'is', 'considered', 'a', 'business', 'expense', 'on', 'a', 'business', 'trip', '?', '[SEP]']),\n",
              "       list(['[CLS]', 'what', 'is', 'considered', 'a', 'business', 'expense', 'on', 'a', 'business', 'trip', '?', '[SEP]'])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4efXpYIypedD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.to_csv(path+\"data-bert/train.csv\", index=False, header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzsyoZ63lsUa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "12012b15-0ce5-420b-dd8b-f54850ecf9f4"
      },
      "source": [
        "train.question.str.len().max()\n",
        "train.ans_cand.str.len().max()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16990"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Sbf58rDiLsN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "bb18c99a-8328-4d5e-e893-1b47ec1c413e"
      },
      "source": [
        "train = train[['qid', 'docid', 'label', 'seq']]\n",
        "train.head(5)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>docid</th>\n",
              "      <th>label</th>\n",
              "      <th>seq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>18850</td>\n",
              "      <td>1</td>\n",
              "      <td>[CLS] What is considered a business expense on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>408058</td>\n",
              "      <td>0</td>\n",
              "      <td>[CLS] What is considered a business expense on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>343708</td>\n",
              "      <td>0</td>\n",
              "      <td>[CLS] What is considered a business expense on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>311069</td>\n",
              "      <td>0</td>\n",
              "      <td>[CLS] What is considered a business expense on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>139094</td>\n",
              "      <td>0</td>\n",
              "      <td>[CLS] What is considered a business expense on...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    qid   docid  label                                                seq\n",
              "0     0   18850      1  [CLS] What is considered a business expense on...\n",
              "20    0  408058      0  [CLS] What is considered a business expense on...\n",
              "21    0  343708      0  [CLS] What is considered a business expense on...\n",
              "22    0  311069      0  [CLS] What is considered a business expense on...\n",
              "23    0  139094      0  [CLS] What is considered a business expense on..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvSBxsoMfEoS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sequences = train.seq.values\n",
        "labels = train.label.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THFL6mOJfb1_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "f95cd028-1ad0-4f96-9e3f-431617cdc4a2"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sequences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sequences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sequences[0])))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  [CLS] What is considered a business expense on a business trip? [SEP] The IRS Guidance pertaining to the subject.  In general the best I can say is your business expense may be deductible.  But it depends on the circumstances and what it is you want to deduct. Travel Taxpayers who travel away from home on business may deduct related   expenses, including the cost of reaching their destination, the cost   of lodging and meals and other ordinary and necessary expenses.   Taxpayers are considered “traveling away from home” if their duties   require them to be away from home substantially longer than an   ordinary day’s work and they need to sleep or rest to meet the demands   of their work. The actual cost of meals and incidental expenses may be   deducted or the taxpayer may use a standard meal allowance and reduced   record keeping requirements. Regardless of the method used, meal   deductions are generally limited to 50 percent as stated earlier.    Only actual costs for lodging may be claimed as an expense and   receipts must be kept for documentation. Expenses must be reasonable   and appropriate; deductions for extravagant expenses are not   allowable. More information is available in Publication 463, Travel,   Entertainment, Gift, and Car Expenses. Entertainment Expenses for entertaining clients, customers or employees may be   deducted if they are both ordinary and necessary and meet one of the   following tests: Directly-related test: The main purpose of the entertainment activity is the conduct of business, business was actually conducted   during the activity and the taxpayer had more than a general   expectation of getting income or some other specific business benefit   at some future time.   Associated test: The entertainment was associated with the active conduct of the taxpayer’s trade or business and occurred directly   before or after a substantial business discussion. Publication 463 provides more extensive explanation of these tests as   well as other limitations and requirements for deducting entertainment   expenses. Gifts Taxpayers may deduct some or all of the cost of gifts given in the   course of their trade or business. In general, the deduction is   limited to $25 for gifts given directly or indirectly to any one   person during the tax year. More discussion of the rules and   limitations can be found in Publication 463. If your LLC reimburses you for expenses outside of this guidance it should be treated as Income for tax purposes. Edit for Meal Expenses: Amount of standard meal allowance.   The standard meal allowance is   the federal M&IE rate. For travel in 2010, the rate for most small   localities in the United States is $46 a day. Source IRS P463 Alternately you could reimburse at a per diem rate [SEP]\n",
            "Tokenized:  ['[CLS]', 'what', 'is', 'considered', 'a', 'business', 'expense', 'on', 'a', 'business', 'trip', '?', '[SEP]', 'the', 'irs', 'guidance', 'pertaining', 'to', 'the', 'subject', '.', 'in', 'general', 'the', 'best', 'i', 'can', 'say', 'is', 'your', 'business', 'expense', 'may', 'be', 'de', '##du', '##ct', '##ible', '.', 'but', 'it', 'depends', 'on', 'the', 'circumstances', 'and', 'what', 'it', 'is', 'you', 'want', 'to', 'de', '##du', '##ct', '.', 'travel', 'taxpayers', 'who', 'travel', 'away', 'from', 'home', 'on', 'business', 'may', 'de', '##du', '##ct', 'related', 'expenses', ',', 'including', 'the', 'cost', 'of', 'reaching', 'their', 'destination', ',', 'the', 'cost', 'of', 'lodging', 'and', 'meals', 'and', 'other', 'ordinary', 'and', 'necessary', 'expenses', '.', 'taxpayers', 'are', 'considered', '“', 'traveling', 'away', 'from', 'home', '”', 'if', 'their', 'duties', 'require', 'them', 'to', 'be', 'away', 'from', 'home', 'substantially', 'longer', 'than', 'an', 'ordinary', 'day', '’', 's', 'work', 'and', 'they', 'need', 'to', 'sleep', 'or', 'rest', 'to', 'meet', 'the', 'demands', 'of', 'their', 'work', '.', 'the', 'actual', 'cost', 'of', 'meals', 'and', 'incident', '##al', 'expenses', 'may', 'be', 'de', '##ducted', 'or', 'the', 'taxpayer', 'may', 'use', 'a', 'standard', 'meal', 'allowance', 'and', 'reduced', 'record', 'keeping', 'requirements', '.', 'regardless', 'of', 'the', 'method', 'used', ',', 'meal', 'de', '##duction', '##s', 'are', 'generally', 'limited', 'to', '50', 'percent', 'as', 'stated', 'earlier', '.', 'only', 'actual', 'costs', 'for', 'lodging', 'may', 'be', 'claimed', 'as', 'an', 'expense', 'and', 'receipts', 'must', 'be', 'kept', 'for', 'documentation', '.', 'expenses', 'must', 'be', 'reasonable', 'and', 'appropriate', ';', 'de', '##duction', '##s', 'for', 'extravagant', 'expenses', 'are', 'not', 'allow', '##able', '.', 'more', 'information', 'is', 'available', 'in', 'publication', '46', '##3', ',', 'travel', ',', 'entertainment', ',', 'gift', ',', 'and', 'car', 'expenses', '.', 'entertainment', 'expenses', 'for', 'entertaining', 'clients', ',', 'customers', 'or', 'employees', 'may', 'be', 'de', '##ducted', 'if', 'they', 'are', 'both', 'ordinary', 'and', 'necessary', 'and', 'meet', 'one', 'of', 'the', 'following', 'tests', ':', 'directly', '-', 'related', 'test', ':', 'the', 'main', 'purpose', 'of', 'the', 'entertainment', 'activity', 'is', 'the', 'conduct', 'of', 'business', ',', 'business', 'was', 'actually', 'conducted', 'during', 'the', 'activity', 'and', 'the', 'taxpayer', 'had', 'more', 'than', 'a', 'general', 'expectation', 'of', 'getting', 'income', 'or', 'some', 'other', 'specific', 'business', 'benefit', 'at', 'some', 'future', 'time', '.', 'associated', 'test', ':', 'the', 'entertainment', 'was', 'associated', 'with', 'the', 'active', 'conduct', 'of', 'the', 'taxpayer', '’', 's', 'trade', 'or', 'business', 'and', 'occurred', 'directly', 'before', 'or', 'after', 'a', 'substantial', 'business', 'discussion', '.', 'publication', '46', '##3', 'provides', 'more', 'extensive', 'explanation', 'of', 'these', 'tests', 'as', 'well', 'as', 'other', 'limitations', 'and', 'requirements', 'for', 'de', '##du', '##cting', 'entertainment', 'expenses', '.', 'gifts', 'taxpayers', 'may', 'de', '##du', '##ct', 'some', 'or', 'all', 'of', 'the', 'cost', 'of', 'gifts', 'given', 'in', 'the', 'course', 'of', 'their', 'trade', 'or', 'business', '.', 'in', 'general', ',', 'the', 'de', '##duction', 'is', 'limited', 'to', '$', '25', 'for', 'gifts', 'given', 'directly', 'or', 'indirectly', 'to', 'any', 'one', 'person', 'during', 'the', 'tax', 'year', '.', 'more', 'discussion', 'of', 'the', 'rules', 'and', 'limitations', 'can', 'be', 'found', 'in', 'publication', '46', '##3', '.', 'if', 'your', 'llc', 'rei', '##mb', '##urse', '##s', 'you', 'for', 'expenses', 'outside', 'of', 'this', 'guidance', 'it', 'should', 'be', 'treated', 'as', 'income', 'for', 'tax', 'purposes', '.', 'edit', 'for', 'meal', 'expenses', ':', 'amount', 'of', 'standard', 'meal', 'allowance', '.', 'the', 'standard', 'meal', 'allowance', 'is', 'the', 'federal', 'm', '&', 'ie', 'rate', '.', 'for', 'travel', 'in', '2010', ',', 'the', 'rate', 'for', 'most', 'small', 'localities', 'in', 'the', 'united', 'states', 'is', '$', '46', 'a', 'day', '.', 'source', 'irs', 'p', '##46', '##3', 'alternately', 'you', 'could', 'rei', '##mb', '##urse', 'at', 'a', 'per', 'die', '##m', 'rate', '[SEP]']\n",
            "Token IDs:  [101, 2054, 2003, 2641, 1037, 2449, 10961, 2006, 1037, 2449, 4440, 1029, 102, 1996, 25760, 8606, 20246, 2000, 1996, 3395, 1012, 1999, 2236, 1996, 2190, 1045, 2064, 2360, 2003, 2115, 2449, 10961, 2089, 2022, 2139, 8566, 6593, 7028, 1012, 2021, 2009, 9041, 2006, 1996, 6214, 1998, 2054, 2009, 2003, 2017, 2215, 2000, 2139, 8566, 6593, 1012, 3604, 26457, 2040, 3604, 2185, 2013, 2188, 2006, 2449, 2089, 2139, 8566, 6593, 3141, 11727, 1010, 2164, 1996, 3465, 1997, 4285, 2037, 7688, 1010, 1996, 3465, 1997, 26859, 1998, 12278, 1998, 2060, 6623, 1998, 4072, 11727, 1012, 26457, 2024, 2641, 1523, 7118, 2185, 2013, 2188, 1524, 2065, 2037, 5704, 5478, 2068, 2000, 2022, 2185, 2013, 2188, 12381, 2936, 2084, 2019, 6623, 2154, 1521, 1055, 2147, 1998, 2027, 2342, 2000, 3637, 2030, 2717, 2000, 3113, 1996, 7670, 1997, 2037, 2147, 1012, 1996, 5025, 3465, 1997, 12278, 1998, 5043, 2389, 11727, 2089, 2022, 2139, 29510, 2030, 1996, 26980, 2089, 2224, 1037, 3115, 7954, 21447, 1998, 4359, 2501, 4363, 5918, 1012, 7539, 1997, 1996, 4118, 2109, 1010, 7954, 2139, 16256, 2015, 2024, 3227, 3132, 2000, 2753, 3867, 2004, 3090, 3041, 1012, 2069, 5025, 5366, 2005, 26859, 2089, 2022, 3555, 2004, 2019, 10961, 1998, 28258, 2442, 2022, 2921, 2005, 12653, 1012, 11727, 2442, 2022, 9608, 1998, 6413, 1025, 2139, 16256, 2015, 2005, 27856, 11727, 2024, 2025, 3499, 3085, 1012, 2062, 2592, 2003, 2800, 1999, 4772, 4805, 2509, 1010, 3604, 1010, 4024, 1010, 5592, 1010, 1998, 2482, 11727, 1012, 4024, 11727, 2005, 14036, 7846, 1010, 6304, 2030, 5126, 2089, 2022, 2139, 29510, 2065, 2027, 2024, 2119, 6623, 1998, 4072, 1998, 3113, 2028, 1997, 1996, 2206, 5852, 1024, 3495, 1011, 3141, 3231, 1024, 1996, 2364, 3800, 1997, 1996, 4024, 4023, 2003, 1996, 6204, 1997, 2449, 1010, 2449, 2001, 2941, 4146, 2076, 1996, 4023, 1998, 1996, 26980, 2018, 2062, 2084, 1037, 2236, 17626, 1997, 2893, 3318, 2030, 2070, 2060, 3563, 2449, 5770, 2012, 2070, 2925, 2051, 1012, 3378, 3231, 1024, 1996, 4024, 2001, 3378, 2007, 1996, 3161, 6204, 1997, 1996, 26980, 1521, 1055, 3119, 2030, 2449, 1998, 4158, 3495, 2077, 2030, 2044, 1037, 6937, 2449, 6594, 1012, 4772, 4805, 2509, 3640, 2062, 4866, 7526, 1997, 2122, 5852, 2004, 2092, 2004, 2060, 12546, 1998, 5918, 2005, 2139, 8566, 11873, 4024, 11727, 1012, 9604, 26457, 2089, 2139, 8566, 6593, 2070, 2030, 2035, 1997, 1996, 3465, 1997, 9604, 2445, 1999, 1996, 2607, 1997, 2037, 3119, 2030, 2449, 1012, 1999, 2236, 1010, 1996, 2139, 16256, 2003, 3132, 2000, 1002, 2423, 2005, 9604, 2445, 3495, 2030, 17351, 2000, 2151, 2028, 2711, 2076, 1996, 4171, 2095, 1012, 2062, 6594, 1997, 1996, 3513, 1998, 12546, 2064, 2022, 2179, 1999, 4772, 4805, 2509, 1012, 2065, 2115, 11775, 24964, 14905, 28393, 2015, 2017, 2005, 11727, 2648, 1997, 2023, 8606, 2009, 2323, 2022, 5845, 2004, 3318, 2005, 4171, 5682, 1012, 10086, 2005, 7954, 11727, 1024, 3815, 1997, 3115, 7954, 21447, 1012, 1996, 3115, 7954, 21447, 2003, 1996, 2976, 1049, 1004, 29464, 3446, 1012, 2005, 3604, 1999, 2230, 1010, 1996, 3446, 2005, 2087, 2235, 19664, 1999, 1996, 2142, 2163, 2003, 1002, 4805, 1037, 2154, 1012, 3120, 25760, 1052, 21472, 2509, 23554, 2017, 2071, 24964, 14905, 28393, 2012, 1037, 2566, 3280, 2213, 3446, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSMKP-TAfjNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "for seq in sequences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Map tokens to their IDs.\n",
        "    encoded_seq = tokenizer.encode(\n",
        "                        seq,                      # Sentence to encode.\n",
        "                        add_special_tokens = False, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_seq)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sequences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}