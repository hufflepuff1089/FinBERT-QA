{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bertQA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c3fb42c889434725b24b20ceab6751a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_972c31c1825e4a7ab13e8d1729fc5be1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_742d3e40d8b2485188addd345e70e8af",
              "IPY_MODEL_ec44d4deb6d84704b55e192013fcda26"
            ]
          }
        },
        "972c31c1825e4a7ab13e8d1729fc5be1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "742d3e40d8b2485188addd345e70e8af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c5f6b4703f67427a973e584334447ffe",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_74017eecd7124f23a5f7bc43f8228fcd"
          }
        },
        "ec44d4deb6d84704b55e192013fcda26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_68ff4e7e6cbb4d85a883d70658414c73",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 232k/232k [00:00&lt;00:00, 421kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d15e32632104827a53fb1e8a8e203c7"
          }
        },
        "c5f6b4703f67427a973e584334447ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "74017eecd7124f23a5f7bc43f8228fcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68ff4e7e6cbb4d85a883d70658414c73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d15e32632104827a53fb1e8a8e203c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySXHdHsEUxNd",
        "colab_type": "code",
        "outputId": "48500b22-5e34-4459-e5a0-6a7213a14f2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-hWS0v0sx7J",
        "colab_type": "code",
        "outputId": "aac83955-459c-4d52-c1e7-8a7f6f602259",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        }
      },
      "source": [
        "import pickle\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from itertools import islice\n",
        "import numpy as np\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import random\n",
        "!pip install transformers\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, BertConfig, BertForSequenceClassification\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from transformers import AdamW\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Setting device on GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "print()\n",
        "\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Set the random seed manually for reproducibility.\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "path = \"drive/My Drive/FiQA/\""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.5.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: tokenizers==0.5.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Using device: cuda\n",
            "\n",
            "Tesla P100-PCIE-16GB\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.0 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBGukeI_cCPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from evaluate import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbIIxiVhU1VL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def take(n, iterable):\n",
        "    \"Return first n items of the iterable as a list\"\n",
        "    return list(islice(iterable, n))\n",
        "\n",
        "def remove_empty(test_set):\n",
        "    for index, row in enumerate(test_set):\n",
        "        for doc in row[1]:\n",
        "            if doc in empty_docs:\n",
        "                del test_set[index]\n",
        "    return test_set\n",
        "\n",
        "def load_pickle(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "def save_pickle(path, data):\n",
        "    with open(path, 'wb') as handle:\n",
        "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def pad_seq(seq, max_seq_len):\n",
        "    # Pad each seq to be the same length to process in batch.\n",
        "    # pad_token = 0\n",
        "    if len(seq) >= max_seq_len:\n",
        "        seq = seq[:max_seq_len]\n",
        "    else:\n",
        "        seq += [0]*(max_seq_len - len(seq))\n",
        "    return seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iCcUYUvb6-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dict mapping of token to idx\n",
        "vocab = load_pickle(path + 'vocab_full.pickle')\n",
        "# dict mapping of docid to doc text\n",
        "docid_to_text = load_pickle(path + 'label_ans.pickle')\n",
        "\n",
        "# dict mapping of qid to question text\n",
        "qid_to_text = load_pickle(path + 'qid_text.pickle')\n",
        "\n",
        "train_qid_rel = load_pickle(path + \"qid_rel_train.pickle\")\n",
        "test_qid_rel = load_pickle(path + \"qid_rel_test.pickle\")\n",
        "valid_qid_rel = load_pickle(path + \"qid_rel_valid.pickle\")\n",
        "\n",
        "train_set = load_pickle(path + 'data/data_train_50.pickle')\n",
        "valid_set = load_pickle(path + 'data/data_valid_50.pickle')\n",
        "\n",
        "test_set = load_pickle(path + 'data/data_test_500_rel.pickle')\n",
        "test_set_full = load_pickle(path + 'data/data_test_500.pickle')\n",
        "\n",
        "empty_docs = load_pickle(path+'empty_docs.pickle')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9_sM2Lrb794",
        "colab_type": "code",
        "outputId": "7e26799c-04ad-469f-b645-af9939fe3554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "train_set = [x for x in train_set if x[1] not in empty_docs]\n",
        "valid_set = [x for x in valid_set if x[1] not in empty_docs]\n",
        "\n",
        "test_set = remove_empty(test_set)\n",
        "test_set_full = remove_empty(test_set_full)\n",
        "\n",
        "print(\"Number of training samples: {}\".format(len(train_set)))\n",
        "print(\"Number of validation samples: {}\".format(len(valid_set)))\n",
        "print(\"Number of test samples: {}\".format(len(test_set)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples: 283707\n",
            "Number of validation samples: 31582\n",
            "Number of test samples: 330\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6npVgMDNewIW",
        "colab_type": "code",
        "outputId": "161c3db4-a0c2-4a8d-cd37-330cc7c55909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "c3fb42c889434725b24b20ceab6751a7",
            "972c31c1825e4a7ab13e8d1729fc5be1",
            "742d3e40d8b2485188addd345e70e8af",
            "ec44d4deb6d84704b55e192013fcda26",
            "c5f6b4703f67427a973e584334447ffe",
            "74017eecd7124f23a5f7bc43f8228fcd",
            "68ff4e7e6cbb4d85a883d70658414c73",
            "0d15e32632104827a53fb1e8a8e203c7"
          ]
        }
      },
      "source": [
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3fb42c889434725b24b20ceab6751a7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXwjgq4zuPzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_to_ans = load_pickle(path+\"data-bert/label_to_ans.pickle\")\n",
        "qid_to_text = load_pickle(path+\"data-bert/qid_to_text.pickle\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZERfpbehdwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_question_token(q_tokens):\n",
        "    c = [\"[CLS]\"]\n",
        "    s = [\"[SEP]\"]\n",
        "    q_tokens = c + q_tokens\n",
        "    q_tokens = q_tokens + s\n",
        "\n",
        "    return q_tokens\n",
        "\n",
        "def add_ans_token(a_tokens):\n",
        "    s = [\"[SEP]\"]\n",
        "    a_tokens = a_tokens + s\n",
        "\n",
        "    return a_tokens\n",
        "\n",
        "def clip(lst):\n",
        "    max_seq_len = 512\n",
        "    if len(lst) > max_seq_len:\n",
        "        lst = lst[:max_seq_len]\n",
        "    else:\n",
        "        lst = lst\n",
        "    \n",
        "    return lst\n",
        "\n",
        "def get_input_ids(sequences, max_seq_len):\n",
        "    # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "    input_ids = []\n",
        "\n",
        "    for seq in sequences:\n",
        "        # `encode` will:\n",
        "        #   (1) Tokenize the sentence.\n",
        "        #   (2) Map tokens to their IDs.\n",
        "        encoded_seq = tokenizer.convert_tokens_to_ids(seq)\n",
        "        \n",
        "        # Add the encoded sentence to the list.\n",
        "        input_ids.append(encoded_seq)\n",
        "\n",
        "    input_ids = pad_sequences(input_ids, maxlen=max_seq_len, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "    return input_ids\n",
        "\n",
        "def get_att_mask(input_ids):\n",
        "    # Create attention masks\n",
        "    attention_masks = []\n",
        "\n",
        "    # For each sentence...\n",
        "    for sent in input_ids:\n",
        "        \n",
        "        # Create the attention mask.\n",
        "        #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "        #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "        att_mask = [int(token_id > 0) for token_id in sent]\n",
        "        \n",
        "        # Store the attention mask for this sentence.\n",
        "        attention_masks.append(att_mask)\n",
        "\n",
        "    return attention_masks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcnub5RAVxJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sequence_df(dataset):\n",
        "    df = pd.DataFrame(dataset)\n",
        "    df = df.rename(columns={0: 'qid', 1: 'pos', 2:'neg'})\n",
        "    df_pos = df[['qid', 'pos']]\n",
        "    df_pos = df_pos.rename(columns={'pos': 'docid'})\n",
        "    df_pos['label'] = df_pos.apply(lambda x: 1, axis=1)\n",
        "    df_pos = df_pos.drop_duplicates()\n",
        "\n",
        "    df_neg = df[['qid', 'neg']]\n",
        "    df_neg = df_neg.rename(columns={'neg': 'docid'})\n",
        "    df_neg['label'] = df_neg.apply(lambda x: 0, axis=1)\n",
        "    data_df = pd.concat([df_pos, df_neg]).sort_values(by=['qid'])\n",
        "\n",
        "    data_df['question'] = data_df['qid'].apply(lambda x: qid_to_text[x])\n",
        "    data_df['ans_cand'] = data_df['docid'].apply(lambda x: label_to_ans[x])\n",
        "    data_df['ques_token'] = data_df['question'].apply(lambda x: add_question_token(x))\n",
        "    data_df['ans_cand'] = data_df['ans_cand'].apply(lambda x: add_ans_token(x))\n",
        "\n",
        "    data_df = data_df[['qid', 'docid', 'label', 'ans_cand','ques_token']]\n",
        "    data_df['seq'] = data_df['ques_token'] + data_df['ans_cand']\n",
        "\n",
        "    data_df['seq_clipped'] = data_df['seq'].apply(clip)\n",
        "    # train['len'] = train['seq_clipped'].apply(lambda x: len(x))\n",
        "\n",
        "    return data_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd6H-9xlrS66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_pairwise_sequence_df(dataset):\n",
        "    df = pd.DataFrame(dataset)\n",
        "    df = df.rename(columns={0: 'qid', 1: 'pos_id', 2:'neg_id'})\n",
        "    df['pos_label'] = df.apply(lambda x: 1, axis=1)\n",
        "    df['neg_label'] = df.apply(lambda x: 0, axis=1)\n",
        "\n",
        "    df['question'] = df['qid'].apply(lambda x: qid_to_text[x])\n",
        "    df['pos_ans'] = df['pos_id'].apply(lambda x: label_to_ans[x])\n",
        "    df['neg_ans'] = df['neg_id'].apply(lambda x: label_to_ans[x])\n",
        "\n",
        "    df['ques_token'] = df['question'].apply(lambda x: add_question_token(x))\n",
        "    df['pos_ans'] = df['pos_ans'].apply(lambda x: add_ans_token(x))\n",
        "    df['neg_ans'] = df['neg_ans'].apply(lambda x: add_ans_token(x))\n",
        "\n",
        "    df = df[['qid', 'pos_id', 'neg_id', 'pos_label', 'neg_label', 'pos_ans', 'neg_ans', 'ques_token']]\n",
        "    df['pos_seq'] = df['ques_token'] + df['pos_ans']\n",
        "    df['neg_seq'] = df['ques_token'] + df['neg_ans']\n",
        "\n",
        "    df['pos_seq_clipped'] = df['pos_seq'].apply(clip)\n",
        "    df['neg_seq_clipped'] = df['neg_seq'].apply(clip)\n",
        "\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YEbteNsrcM6",
        "colab_type": "text"
      },
      "source": [
        "## **Pairwise**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjB1w2ZjrXAb",
        "colab_type": "code",
        "outputId": "10290662-0b2a-4bc2-fc7c-fd1cf77672fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "trainset = get_pairwise_sequence_df(train_set)\n",
        "validset = get_pairwise_sequence_df(valid_set)\n",
        "\n",
        "# Get the lists of sentences and their labels.\n",
        "train_pos_seq = trainset.pos_seq_clipped.values\n",
        "train_neg_seq = trainset.neg_seq_clipped.values\n",
        "train_pos_labels = trainset.pos_label.values\n",
        "train_neg_labels = trainset.neg_label.values\n",
        "\n",
        "valid_pos_seq = validset.pos_seq_clipped.values\n",
        "valid_neg_seq = validset.neg_seq_clipped.values\n",
        "valid_pos_labels = validset.pos_label.values\n",
        "valid_neg_labels = validset.neg_label.values\n",
        "\n",
        "print(len(train_pos_seq))\n",
        "print(len(valid_pos_seq))\n",
        "\n",
        "# train_pos_seq = train_pos_seq[:300]\n",
        "# train_neg_seq = train_neg_seq[:300]\n",
        "# train_pos_labels = train_pos_labels[:300]\n",
        "# train_neg_labels = train_neg_labels[:300]\n",
        "\n",
        "# valid_pos_seq = valid_pos_seq[:30]\n",
        "# valid_neg_seq = valid_neg_seq[:30]\n",
        "# valid_pos_labels = valid_pos_labels[:30]\n",
        "# valid_neg_labels = valid_neg_labels[:30]\n",
        "\n",
        "max_seq_len = 512\n",
        "\n",
        "train_pos_input = get_input_ids(train_pos_seq, max_seq_len)\n",
        "train_neg_input = get_input_ids(train_neg_seq, max_seq_len)\n",
        "valid_pos_input = get_input_ids(valid_pos_seq, max_seq_len)\n",
        "valid_neg_input = get_input_ids(valid_neg_seq, max_seq_len)\n",
        "\n",
        "train_pos_mask = get_att_mask(train_pos_input)\n",
        "train_neg_mask = get_att_mask(train_neg_input)\n",
        "valid_pos_mask = get_att_mask(valid_pos_input)\n",
        "valid_neg_mask = get_att_mask(valid_neg_input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "283707\n",
            "31582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNabMgS5-xtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save_pickle(path+'/data-bert/train_pos_labels.pickle', train_pos_labels)\n",
        "# save_pickle(path+'/data-bert/train_neg_labels.pickle', train_neg_labels)\n",
        "# save_pickle(path+'/data-bert/valid_pos_labels.pickle', valid_pos_labels)\n",
        "# save_pickle(path+'/data-bert/valid_neg_labels.pickle', valid_neg_labels)\n",
        "\n",
        "save_pickle(path+'/data-bert/train_pos_input_512.pickle', train_pos_input)\n",
        "save_pickle(path+'/data-bert/train_neg_input_512.pickle', train_neg_input)\n",
        "save_pickle(path+'/data-bert/valid_pos_input_512.pickle', valid_pos_input)\n",
        "save_pickle(path+'/data-bert/valid_neg_input_512.pickle', valid_neg_input)\n",
        "\n",
        "save_pickle(path+'/data-bert/train_pos_mask_512.pickle', train_pos_mask)\n",
        "save_pickle(path+'/data-bert/train_neg_mask_512.pickle', train_neg_mask)\n",
        "save_pickle(path+'/data-bert/valid_pos_mask_512.pickle', valid_pos_mask)\n",
        "save_pickle(path+'/data-bert/valid_neg_mask_512.pickle', valid_neg_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkpbuKiD_jlx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_pos_labels = load_pickle(path+'/data-bert/train_pos_labels.pickle')\n",
        "train_neg_labels = load_pickle(path+'/data-bert/train_neg_labels.pickle')\n",
        "valid_pos_labels = load_pickle(path+'/data-bert/valid_pos_labels.pickle')\n",
        "valid_neg_labels = load_pickle(path+'/data-bert/valid_neg_labels.pickle')\n",
        "\n",
        "train_pos_input = load_pickle(path+'/data-bert/train_pos_input_512.pickle')\n",
        "train_neg_input = load_pickle(path+'/data-bert/train_neg_input_512.pickle')\n",
        "valid_pos_input = load_pickle(path+'/data-bert/valid_pos_input_512.pickle')\n",
        "valid_neg_input = load_pickle(path+'/data-bert/valid_neg_input_512.pickle')\n",
        "\n",
        "train_pos_mask = load_pickle(path+'/data-bert/train_pos_mask_512.pickle')\n",
        "train_neg_mask = load_pickle(path+'/data-bert/train_neg_mask_512.pickle')\n",
        "valid_pos_mask = load_pickle(path+'/data-bert/valid_pos_mask_512.pickle')\n",
        "valid_neg_mask = load_pickle(path+'/data-bert/valid_neg_mask_512.pickle')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1vGWJhkrkkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_pos_inputs = torch.tensor(train_pos_input)\n",
        "train_neg_inputs = torch.tensor(train_neg_input)\n",
        "valid_pos_inputs = torch.tensor(valid_pos_input)\n",
        "valid_neg_inputs = torch.tensor(valid_neg_input)\n",
        "\n",
        "train_pos_labels = torch.tensor(train_pos_labels)\n",
        "train_neg_labels = torch.tensor(train_neg_labels)\n",
        "valid_pos_labels = torch.tensor(valid_pos_labels)\n",
        "valid_neg_labels = torch.tensor(valid_neg_labels)\n",
        "\n",
        "train_pos_masks = torch.tensor(train_pos_mask)\n",
        "train_neg_masks = torch.tensor(train_neg_mask)\n",
        "valid_pos_masks = torch.tensor(valid_pos_mask)\n",
        "valid_neg_masks = torch.tensor(valid_neg_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wr11jao6rmmJ",
        "colab_type": "code",
        "outputId": "8a8a9e7c-a64f-4b29-ca87-895866f2623a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(len(train_pos_inputs))\n",
        "print(len(valid_pos_inputs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "283707\n",
            "31582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI6_x69UrpPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_pos_inputs, train_pos_masks, train_pos_labels, train_neg_inputs, train_neg_masks, train_neg_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(valid_pos_inputs, valid_pos_masks, valid_pos_labels, valid_neg_inputs, valid_neg_masks, valid_neg_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sShSbfK-rw0N",
        "colab_type": "code",
        "outputId": "8887f906-0f8f-4a56-fe64-2638862f18a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(len(train_dataloader))\n",
        "print(len(validation_dataloader))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35464\n",
            "3948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFHbkOpYry-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BertPairwiseClassifier(nn.Module):\n",
        "    def __init__(self, bert):\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.config = BertConfig()\n",
        "        self.num_labels = self.config.num_labels\n",
        "        self.bert = bert\n",
        "        self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(self.config.hidden_size, self.config.num_labels)\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, labels=None):\n",
        "\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, position_ids=position_ids, head_mask=head_mask, inputs_embeds=inputs_embeds)\n",
        "\n",
        "        pooled_output = outputs[1]\n",
        "\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMnLBtsXr3SJ",
        "colab_type": "code",
        "outputId": "3474f063-1516-44ea-c9b0-c452a0d8ae19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "model = BertPairwiseClassifier(bert)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertPairwiseClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-oyliUaudAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pairwise_loss(pos_scores, neg_scores):\n",
        "\n",
        "    cross_entropy_loss = -torch.log(pos_scores) - torch.log(1 - neg_scores)\n",
        "\n",
        "    margin = 0.2\n",
        "\n",
        "    hinge_loss = torch.max(torch.tensor(0, dtype=torch.float).to(device), margin - pos_scores + neg_scores)\n",
        "\n",
        "    loss = (0.5 * cross_entropy_loss + 0.5 * hinge_loss)\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezhNI5PouC_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_pairwise(model, train_dataloader, optimizer):\n",
        "\n",
        "    # Store the average loss after each epoch so we can plot them.\n",
        "    loss_values = []\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
        "\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        pos_input = batch[0].to(device)\n",
        "        pos_mask = batch[1].to(device)\n",
        "        pos_labels = batch[2].to(device)\n",
        "\n",
        "        neg_input = batch[3].to(device)\n",
        "        neg_mask = batch[4].to(device)\n",
        "        neg_labels = batch[5].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        pos_scores = torch.sigmoid(model(pos_input, token_type_ids=None, attention_mask=pos_mask, labels=pos_labels))[:,1]\n",
        "        neg_scores = torch.sigmoid(model(neg_input, token_type_ids=None, attention_mask=neg_mask, labels=neg_labels))[:,1]\n",
        "\n",
        "        loss = pairwise_loss(pos_scores, neg_scores).mean()\n",
        "        \n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "        # Accumulate the training loss over all of the batches\n",
        "        total_loss += loss.item()\n",
        "    \n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        optimizer.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    return avg_train_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TVwYxdw5Qx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate_pairwise(model, validation_dataloader):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_loss = 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in tqdm(validation_dataloader):\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        pos_input, pos_mask, pos_labels, neg_input, neg_mask, neg_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "            pos_scores = torch.sigmoid(model(pos_input, token_type_ids=None, attention_mask=pos_mask, labels=pos_labels))[:,1]\n",
        "            neg_scores = torch.sigmoid(model(neg_input, token_type_ids=None, attention_mask=neg_mask, labels=neg_labels))[:,1]\n",
        "\n",
        "        loss = pairwise_loss(pos_scores, neg_scores).mean()\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(validation_dataloader) \n",
        "\n",
        "    return avg_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwVMd1DQyW2G",
        "colab_type": "code",
        "outputId": "b5c99ea6-cfe8-4a84-bff8-4a2ec22c6197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr=0.001)\n",
        "\n",
        "# Lowest validation lost\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "n_epochs = 2\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    # Evaluate training loss\n",
        "    train_loss = train_pairwise(model, train_dataloader, optimizer)\n",
        "    # Evaluate validation loss\n",
        "    valid_loss = validate_pairwise(model, validation_dataloader)\n",
        "    \n",
        "    # At each epoch, if the validation loss is the best\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), path + 'model/' + str(epoch+1)+'_model-bert-pairwise.pt')\n",
        "\n",
        "    print(\"\\n\\n Epoch {}:\".format(epoch+1))\n",
        "    print(\"\\t Train Loss: {}\".format(round(train_loss, 3)))\n",
        "    print(\"\\t Validation Loss: {}\\n\".format(round(valid_loss, 3)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 616/35464 [08:58<8:27:20,  1.14it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5hb3gwfgrYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), path + 'model/2_model-bert-pairwise.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hIxS5Hv8reH",
        "colab_type": "code",
        "outputId": "ec3bf373-b7cc-43b5-ba33-831414b8dbab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print('Memory Usage:')\n",
        "print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory Usage:\n",
            "Allocated: 15.1 GB\n",
            "Cached:    15.2 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKxNW3iprhg7",
        "colab_type": "text"
      },
      "source": [
        "## **Pointwise**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc1x_WQ9lCXu",
        "colab_type": "code",
        "outputId": "db0f7a64-e905-4a2c-d9ea-de9fc416c388",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "trainset = get_sequence_df(train_set)\n",
        "validset = get_sequence_df(valid_set)\n",
        "\n",
        "# Get the lists of sentences and their labels.\n",
        "train_sequences = trainset.seq_clipped.values\n",
        "train_labels = trainset.label.values\n",
        "\n",
        "valid_sequences = validset.seq_clipped.values\n",
        "valid_labels = validset.label.values\n",
        "\n",
        "print(len(train_sequences))\n",
        "print(len(valid_sequences))\n",
        "\n",
        "train_sequences = train_sequences[:3000]\n",
        "train_labels = train_labels[:3000]\n",
        "\n",
        "valid_sequences = valid_sequences[:300]\n",
        "valid_labels = valid_labels[:300]\n",
        "\n",
        "max_seq_len = 512\n",
        "\n",
        "train_input = get_input_ids(train_sequences, max_seq_len)\n",
        "valid_input = get_input_ids(valid_sequences, max_seq_len)\n",
        "\n",
        "train_att_mask = get_att_mask(train_input)\n",
        "valid_att_mask = get_att_mask(valid_input)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "298401\n",
            "33143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-uCr23oIubG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # train_labels = trainset.label.values\n",
        "# # valid_labels = validset.label.values\n",
        "\n",
        "# # save_pickle(path+'/data-bert/train_labels.pickle', train_labels)\n",
        "# # save_pickle(path+'/data-bert/valid_labels.pickle', valid_labels)\n",
        "\n",
        "# save_pickle(path+'/data-bert/train_input_512.pickle', train_input)\n",
        "# save_pickle(path+'/data-bert/valid_input_512.pickle', valid_input)\n",
        "# save_pickle(path+'/data-bert/train_mask_512.pickle', train_att_mask)\n",
        "# save_pickle(path+'/data-bert/valid_mask_512.pickle', valid_att_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI3labKDIT3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_input = load_pickle(path+'/data-bert/train_input.pickle')\n",
        "# valid_input = load_pickle(path+'/data-bert/valid_input.pickle')\n",
        "# train_att_mask = load_pickle(path+'/data-bert/train_mask.pickle')\n",
        "# valid_att_mask = load_pickle(path+'/data-bert/valid_mask.pickle')\n",
        "\n",
        "train_input = load_pickle(path+'/data-bert/train_input_512.pickle')\n",
        "valid_input = load_pickle(path+'/data-bert/valid_input_512.pickle')\n",
        "train_att_mask = load_pickle(path+'/data-bert/train_mask_512.pickle')\n",
        "valid_att_mask = load_pickle(path+'/data-bert/valid_mask_512.pickle')\n",
        "\n",
        "train_labels = load_pickle(path+'/data-bert/train_labels.pickle')\n",
        "valid_labels = load_pickle(path+'/data-bert/valid_labels.pickle')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy1wj92aI4hD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_input)\n",
        "validation_inputs = torch.tensor(valid_input)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(valid_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_att_mask)\n",
        "validation_masks = torch.tensor(valid_att_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcigYAsxypBs",
        "colab_type": "code",
        "outputId": "4ec6baff-9c58-4eef-e8aa-e355a087655e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(len(train_input))\n",
        "print(len(valid_input))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3000\n",
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P4Lb1dzK3Ko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjVUsNKVhXDn",
        "colab_type": "code",
        "outputId": "015f6e3d-3129-404f-cd37-7fa977714e00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(len(train_dataloader))\n",
        "print(len(validation_dataloader))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "375\n",
            "38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14DFmK3GM7LU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmJJeoxC4NKu",
        "colab_type": "text"
      },
      "source": [
        "## **Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpM6uIwJ5GSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "    def __init__(self, bert):\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.config = BertConfig.from_pretrained(path + 'model/fin_model/config.json')\n",
        "        # self.config = BertConfig()\n",
        "        self.num_labels = self.config.num_labels\n",
        "        self.bert = bert\n",
        "        self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(self.config.hidden_size, self.config.num_labels)\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, labels=None):\n",
        "\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, position_ids=position_ids, head_mask=head_mask, inputs_embeds=inputs_embeds)\n",
        "\n",
        "        pooled_output = outputs[1]\n",
        "\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            outputs = (loss,) + outputs\n",
        "\n",
        "        return outputs  # (loss), logits, (hidden_states), (attentions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5e4BOsNh3Sw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = path + 'model/fin_model/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naoa-MQF_lwE",
        "colab_type": "code",
        "outputId": "7a7c36ec-5612-460b-c046-cd0984581b0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "bert = BertModel.from_pretrained(model_path)\n",
        "# model = BertForSequenceClassification.from_pretrained(model_path, cache_dir=None)\n",
        "\n",
        "model = BertClassifier(bert)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDc45R4mjGDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_dataloader, optimizer):\n",
        "\n",
        "    # Store the average loss after each epoch so we can plot them.\n",
        "    loss_values = []\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
        "\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        logits = outputs[1]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "        # Accumulate the training loss over all of the batches\n",
        "        total_loss += loss.item()\n",
        "    \n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        optimizer.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    acc = eval_accuracy/nb_eval_steps\n",
        "\n",
        "    return avg_train_loss, acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNhQobcGke2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(model, validation_dataloader):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_loss = 0\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in tqdm(validation_dataloader):\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask,\n",
        "                            labels=b_labels)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "\n",
        "        logits = outputs[1]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    acc = eval_accuracy/nb_eval_steps\n",
        "    avg_loss = total_loss / len(validation_dataloader) \n",
        "\n",
        "    return avg_loss, acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut7wlYPSlZcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3lU_QLEl4lY",
        "colab_type": "code",
        "outputId": "2184fde5-8d12-4c96-dca5-591fcb72bc20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "# Lowest validation lost\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "n_epochs = 2\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    # Evaluate training loss\n",
        "    train_loss, train_acc = train(model, train_dataloader, optimizer)\n",
        "    \n",
        "    # Evaluate validation loss\n",
        "    valid_loss, valid_acc = validate(model, validation_dataloader)\n",
        "    \n",
        "    # At each epoch, if the validation loss is the best\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), path + 'model/' + str(epoch+1)+'_model-finbert-small.pt')\n",
        "\n",
        "    print(\"\\n\\n Epoch {}:\".format(epoch+1))\n",
        "    print(\"\\t Train Loss: {} | Train Accuracy: {}%\".format(round(train_loss, 3), round(train_acc*100, 2)))\n",
        "    print(\"\\t Validation Loss: {} | Validation Accuracy: {}%\\n\".format(round(valid_loss, 3), round(valid_acc*100, 2)))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 375/375 [02:50<00:00,  2.21it/s]\n",
            "100%|██████████| 38/38 [00:05<00:00,  7.16it/s]\n",
            "  0%|          | 0/375 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " Epoch 1:\n",
            "\t Train Loss: 0.475 | Train Accuracy: 96.2%\n",
            "\t Validation Loss: 0.469 | Validation Accuracy: 97.37%\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 375/375 [02:50<00:00,  2.20it/s]\n",
            "100%|██████████| 38/38 [00:05<00:00,  7.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " Epoch 2:\n",
            "\t Train Loss: 0.472 | Train Accuracy: 96.27%\n",
            "\t Validation Loss: 0.469 | Validation Accuracy: 97.37%\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCVZwbcZqxl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), path + 'model/2_model-finbert-small.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE1ghzszv_0D",
        "colab_type": "code",
        "outputId": "0c351ceb-65d9-4745-bb2a-f473e1376859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print(torch.cuda.get_device_name(0))\n",
        "print('Memory Usage:')\n",
        "print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla P100-PCIE-16GB\n",
            "Memory Usage:\n",
            "Allocated: 4.2 GB\n",
            "Cached:    10.6 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y_hXQeACoNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for row in test_set:\n",
        "    row[2] = [x for x in row[2] if x is not 0]\n",
        "\n",
        "for row in test_set_full:\n",
        "    row[2] = [x for x in row[2] if x is not 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT0cIadqEdNp",
        "colab_type": "code",
        "outputId": "cdfa4a2d-881e-4238-928c-95be93420267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "test_df = pd.DataFrame(test_set)\n",
        "test_df = test_df.rename(columns={0: 'qid', 1: 'pos', 2:'cand'})\n",
        "# test_df = test_df[['qid', 'cand']]\n",
        "\n",
        "test_df.head(5)\n",
        "\n",
        "test_pos = test_df[['qid', 'pos']]\n",
        "test_pos = test_pos.explode('pos')\n",
        "test_pos = test_pos.rename(columns={'pos': 'docid'})\n",
        "test_pos['label'] = test_pos.apply(lambda x: 1, axis=1)\n",
        "\n",
        "len(test_pos)\n",
        "\n",
        "test_neg = test_df[['qid', 'cand']]\n",
        "test_neg = test_neg.explode('cand')\n",
        "test_neg = test_neg.rename(columns={'cand': 'docid'})\n",
        "test_neg ['label'] = test_neg .apply(lambda x: 0, axis=1)\n",
        "\n",
        "test_neg.head(5)\n",
        "\n",
        "test_data = pd.concat([test_pos, test_neg]).sort_values(by=['qid'])\n",
        "\n",
        "test_data['question'] = test_data['qid'].apply(lambda x: qid_to_text[x])\n",
        "test_data['ans_cand'] = test_data['docid'].apply(lambda x: label_to_ans[x])\n",
        "test_data['ques_token'] = test_data['question'].apply(lambda x: add_question_token(x))\n",
        "test_data['ans_cand'] = test_data['ans_cand'].apply(lambda x: add_ans_token(x))\n",
        "\n",
        "test_data = test_data[['qid', 'docid', 'label', 'ans_cand','ques_token']]\n",
        "test_data['seq'] = test_data['ques_token'] + test_data['ans_cand']\n",
        "test_data['seq_clipped'] = test_data['seq'].apply(clip)\n",
        "\n",
        "test_data.head(5)\n",
        "\n",
        "docid_map = test_data[['docid', 'seq_clipped']]\n",
        "test_docid_to_seq = {}\n",
        "\n",
        "for index, row in docid_map.iterrows():\n",
        "    test_docid_to_seq[row['docid']] = row['seq_clipped']\n",
        "\n",
        "print(take(5, test_docid_to_seq.items()))\n",
        "\n",
        "save_pickle(path+'data-bert/test_docid_to_seq_512.pickle', test_docid_to_seq)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(14255, ['[CLS]', 'what', 'is', 'the', 'easiest', 'way', 'to', 'back', '-', 'test', 'index', 'funds', 'and', 'et', '##fs', '?', '[SEP]', 'yes', 'you', 'can', 'claim', 'your', 'business', 'de', '##duction', '##s', 'if', 'you', 'are', 'not', 'making', 'any', 'income', 'yet', '.', 'but', 'first', 'you', 'should', 'decide', 'what', 'structure', 'you', 'want', 'to', 'have', 'for', 'your', 'business', '.', 'either', 'a', 'company', 'structure', 'or', 'a', 'sole', 'trader', 'or', 'partnership', '.', 'company', 'structure', 'if', 'you', 'choose', 'a', 'company', 'structure', '(', 'which', 'is', 'more', 'expensive', 'to', 'set', 'up', ')', 'you', 'would', 'claim', 'your', 'de', '##duction', '##s', 'but', 'no', 'income', '.', 'so', 'you', 'would', 'be', 'making', 'a', 'loss', ',', 'and', 'continue', 'making', 'losses', 'until', 'your', 'income', 'from', 'the', 'business', 'exceed', 'your', 'expenses', '.', 'so', 'these', 'losses', 'will', 'remain', 'inside', 'the', 'company', 'and', 'can', 'be', 'carried', 'forward', 'to', 'future', 'income', 'years', 'when', 'you', 'are', 'making', 'profits', 'to', 'offset', 'these', 'profits', '.', 'refer', 'to', 'at', '##o', '-', 'company', 'tax', 'losses', 'for', 'more', 'information', '.', 'sole', 'trader', 'of', 'partnership', 'structure', 'if', 'you', 'choose', 'to', 'be', 'a', 'sole', 'trader', 'or', 'a', 'partnership', 'and', 'your', 'business', 'makes', 'a', 'loss', 'you', 'must', 'check', 'the', 'non', '-', 'commercial', 'loss', 'rules', 'to', 'see', 'if', 'you', 'can', 'offset', 'the', 'loss', 'against', 'your', 'income', 'from', 'other', 'sources', ',', 'such', 'as', 'wages', '.', 'in', 'order', 'to', 'offset', 'your', 'business', 'losses', 'against', 'your', 'other', 'income', 'your', 'business', 'must', 'pass', 'one', 'of', 'these', 'tests', ':', 'if', 'you', 'don', \"'\", 't', 'pass', 'any', 'of', 'these', 'tests', ',', 'which', 'being', 'a', 'start', '-', 'up', 'you', 'most', 'likely', 'won', \"'\", 't', ',', 'you', 'must', 'carry', 'forward', 'your', 'business', 'losses', 'until', 'an', 'income', 'year', 'in', 'which', 'you', 'do', 'pass', 'one', 'of', 'the', 'tests', ',', 'then', 'you', 'can', 'offset', 'it', 'against', 'your', 'other', 'income', '.', 'this', 'is', 'what', 'differentiate', '##s', 'a', 'legitimate', 'business', 'from', 'someone', 'having', 'a', 'hobby', ',', 'because', 'unless', 'you', 'start', 'making', 'at', 'least', '$', '20', ',', '000', 'in', 'sales', 'income', '(', 'the', 'easiest', 'test', 'to', 'pass', ')', 'you', 'cannot', 'use', 'your', 'business', 'losses', 'against', 'your', 'other', 'income', '.', 'refer', 'to', 'at', '##o', '-', 'non', '-', 'commercial', 'losses', 'for', 'more', 'information', '.', '[SEP]']), (153377, ['[CLS]', 'where', 'do', 'expense', 'ratios', 'show', 'up', 'on', 'my', 'statement', '?', '[SEP]', 'hobby', 'expenses', 'are', 'not', 'tax', 'de', '##du', '##ct', '##ible', '.', 'business', 'expenses', 'are', ',', 'but', 'only', 'if', 'it', \"'\", 's', 'a', 'bon', '##a', 'fide', 'business', '.', 'first', 'they', 'look', 'at', 'profit', '##ability', ':', 'if', 'you', 'reported', 'a', 'net', 'profit', '(', 'i', '.', 'e', '.', 'paid', 'taxes', ')', 'in', 'your', 'first', '3', 'years', ',', 'they', 'will', 'believe', 'you', 'ran', '##t', 'on', 'youtube', 'for', 'a', 'living', '.', 'remember', ',', 'by', 'the', 'time', 'they', 'get', 'around', 'to', 'audit', '##ing', 'you', ',', 'you', \"'\", 'll', 'likely', 'be', 'well', 'into', ',', 'or', 'through', ',', 'your', 'third', 'year', '.', 'there', 'is', 'an', 'exception', 'for', 'farms', '.', 'other', 'than', 'that', ',', 'if', 'you', 'lose', 'money', 'year', 'after', 'year', ',', 'you', 'better', 'be', 'able', 'to', 'show', 'that', 'you', 'look', ',', 'walk', 'and', 'qu', '##ack', 'like', 'a', 'business', ';', 'and', 'one', 'with', 'a', 'reasonable', 'business', 'reason', 'for', 'delayed', 'profit', '##ability', '.', 'for', 'instance', 'netflix', \"'\", 's', 'old', 'business', 'model', 'of', 'mail', '##ing', 'dvds', 'had', 'very', 'high', 'fixed', 'infrastructure', 'expense', 'that', 'took', 'years', 'to', 'turn', 'profitable', ',', 'but', 'was', 'a', 'very', 'sensible', 'model', '.', 'they', \"'\", 're', 'fine', 'with', 'that', '.', 'pets', '.', 'com', 'swan', '##di', '##ved', 'into', 'oblivion', 'but', 'they', 'earnest', '##ly', 'tried', '.', 'they', \"'\", 're', 'fine', 'with', 'that', 'too', '.', 'you', 'can', \"'\", 't', 'mix', 'all', 'your', 'activities', '.', 'if', 'you', \"'\", 're', 'an', 'electric', '##ian', 'specializing', 'in', 'io', '##t', 'and', 'smart', 'homes', ',', 'can', 'you', 'de', '##du', '##ct', 'a', 'trip', 'to', 'the', 'ce', '##s', 'trade', 'show', ',', 'you', 'bet', '.', 'black', '##hat', 'conference', ',', 'ar', '##gua', '##ble', '.', 'se', '##s', '?', 'no', 'way', '.', 'now', 'if', 'you', 'had', 'a', 'second', 'business', 'of', 'a', 'product', '-', 'rec', '##o', 'site', 'which', 'profit', '##ed', 'by', 'ads', 'and', 'affiliate', 'links', ',', 'then', 'se', '##s', 'would', 'be', 'fine', 'to', 'de', '##du', '##ct', 'from', 'that', 'business', '.', 'but', 'if', 'this', 'second', 'business', 'loses', 'money', 'every', 'year', ',', 'it', \"'\", 's', 'a', 'hobby', 'and', 'not', 'de', '##du', '##ct', '##ible', 'at', 'all', '.', 'that', 'person', 'would', 'want', 'separate', 'accounting', 'books', 'for', 'the', 'electric', '##ian', 'and', 'web', '##master', 'businesses', '.', 'that', \"'\", 's', 'a', 'basic', '\"', 'duck', 'test', '\"', 'of', 'a', 'business', 'vs', '.', 'a', 'hobby', '.', 'you', 'need', 'to', 'be', 'able', 'to', 'show', 'how', 'each', 'business', 'gets', 'income', 'and', 'pays', 'expense', 'separate', 'from', 'every', 'other', 'business', 'and', 'your', 'personal', 'life', '.', 'it', \"'\", 's', 'a', 'best', '-', 'practice', 'to', 'give', 'each', 'business', 'a', 'separate', 'checking', 'account', 'and', 'check', '##book', '.', 'you', 'don', \"'\", 't', 'need', 'to', 'risk', 'tax', 'penalties', 'on', 'a', 'business', '-', 'la', '##rva', 'that', 'may', 'never', 'pup', '##ate', '.', 'you', 'can', 'amend', 'your', 'taxes', 'up', 'to', '3', 'years', 'after', 'the', 'proper', 'filing', 'date', '.', 'i', 'save', 'my', 'expense', 'rec', '##ie', '##pts', 'for', 'each', 'tax', 'year', ',', 'and', 'if', 'a', 'business', 'becomes', 'just', '##if', '##iable', ',', 'i', 'go', 'back', 'and', 'amend', 'past', 'years', \"'\", 'tax', 'forms', ',', 'taking', 'those', 'de', '##duction', '##s', '.', 'irs', 'gives', 'me', 'a', 'ref', '##und', 'check', ',', 'with', 'interest', '!', '[SEP]']), (581265, ['[CLS]', 'understanding', 'sec', 'filing', '##s', '[SEP]', 'in', 'the', 'us', 'tax', 'system', ',', 'you', 'cannot', '\"', 'write', '-', 'off', '\"', 'capital', 'assets', '.', 'you', 'have', 'to', 'de', '##pre', '##cia', '##te', 'them', ',', 'with', 'very', 'specific', 'exceptions', '.', 'so', 'while', 'you', 'may', 'be', 'purchasing', '$', '450', '##0', 'of', 'equipment', ',', 'your', 'de', '##duction', 'may', 'be', 'significantly', 'less', '.', 'for', 'example', ',', 'computers', 'are', 'de', '##pre', '##cia', '##ted', 'over', 'the', 'period', 'of', '5', 'years', ',', 'so', 'if', 'you', 'bought', 'a', '$', '1000', 'computer', '-', 'you', 'write', 'off', '$', '200', '/', 'year', 'until', 'it', 'is', 'completely', 'de', '##pre', '##cia', '##ted', ',', 'not', '$', '1000', 'at', 'once', '.', 'there', 'are', 'exceptions', 'however', ',', 'for', 'example', '-', 'ir', '##c', 'sec', '.', '179', 'is', 'one', 'of', 'them', '.', 'but', 'you', 'should', 'talk', 'to', 'a', 'tax', 'adviser', '(', 'ea', '/', 'cp', '##a', 'licensed', 'in', 'your', 'state', ')', 'about', 'whether', 'it', 'is', 'applicable', 'to', 'the', 'specific', 'expense', 'you', 'want', 'to', '\"', 'write', 'off', '\"', 'and', 'to', 'what', 'extent', '.', 'also', ',', 'keep', 'in', 'mind', 'that', 'state', 'laws', 'may', 'not', 'conform', 'to', 'the', 'federal', 'ir', '##c', '.', 'while', 'you', 'may', 'be', 'able', 'to', 'use', 'sec', '.', '179', 'or', 'other', 'exceptions', 'and', 'de', '##du', '##ct', 'your', 'expenses', 'on', 'your', 'federal', 'return', ',', 'you', 'may', 'end', 'up', 'with', 'a', 'whole', 'different', 'set', 'of', 'de', '##duction', '##s', 'on', 'your', 'state', 'return', '.', 'and', 'last', 'but', 'not', 'least', ':', 'equipment', 'that', 'you', 'de', '##pre', '##cia', '##ted', 'or', 'otherwise', '\"', 'wrote', 'off', '\"', 'that', 'is', 'later', 'sold', '-', 'is', 'income', 'to', 'you', ',', 'since', 'de', '##pre', '##ciation', '/', 'de', '##duction', 'reduces', 'basis', '.', 'ah', ',', 'and', 'keep', 'in', 'mind', '-', 'the', 'irs', 'frowns', 'upon', 'schedule', 'c', 'business', 'that', 'consistently', 'show', 'losses', '.', 'if', 'you', 'have', 'losses', 'for', 'more', 'than', '3', 'in', 'the', 'last', '5', 'years', '-', 'your', 'business', 'may', 'be', 'classified', 'as', '\"', 'hobby', '\"', ',', 'and', 'de', '##duction', '##s', 'may', 'be', 'di', '##sal', '##lowe', '##d', '.', 'but', 'the', 'bottom', 'line', 'is', 'that', 'yes', ',', 'it', 'is', 'possible', 'to', 'end', 'up', 'with', '0', 'tax', 'liability', 'with', 'business', 'income', 'offset', 'by', 'business', 'de', '##duction', '##s', '.', 'however', ',', 'not', 'for', 'prolonged', 'periods', 'of', 'time', '(', 'not', 'for', 'years', 'consistently', ',', 'but', 'first', 'year', 'may', 'fly', ')', '.', 'again', '-', 'you', 'should', 'talk', 'to', 'a', 'licensed', 'tax', 'adviser', '(', 'ea', '/', 'cp', '##a', 'licensed', 'in', 'your', 'state', ')', '.', 'it', 'is', 'well', 'worth', 'the', 'money', '.', 'do', 'not', 'rely', 'on', 'answers', 'on', 'free', 'internet', 'forums', 'as', 'a', 'tax', 'advice', '-', 'it', 'is', 'not', '.', '[SEP]']), (515690, ['[CLS]', 'is', 'there', 'an', 'advantage', 'to', 'a', 'traditional', 'but', 'non', '-', 'de', '##du', '##ctable', 'ira', 'over', 'a', 'taxa', '##ble', 'account', '?', '[', 'duplicate', ']', '[SEP]', 'i', 'don', \"'\", 't', 'quite', 'understand', 'your', 'thought', 'process', 'here', '.', 'first', ',', 'in', 'a', 'tax', '-', 'advantage', '##d', 'retirement', 'account', 'you', 'are', 'not', 'allowed', 'to', 'engage', 'in', 'a', 'transaction', 'with', 'yourself', '.', 'if', 'you', 'just', 'want', 'to', 'run', 'a', 'business', 'and', 'be', 'able', 'to', 'write', 'off', 'expenses', ',', 'how', 'is', 'using', 'the', 'self', '-', 'directed', 'ira', 'relevant', '?', 'you', 'can', 'either', 'buy', 'the', 'condo', 'using', 'your', 'tax', '-', 'advantage', '##d', 'account', 'and', 'rent', 'it', 'out', 'to', 'regular', 'tenants', '.', 'or', 'you', 'buy', 'the', 'condo', 'yourself', 'using', 'your', 'own', 'money', 'and', 'then', 'operate', 'your', 'business', 'so', 'you', 'can', 'de', '##du', '##ct', 'business', 'expenses', 'from', 'doing', 'so', '.', '401', '##k', \"'\", 's', 'allow', 'you', 'to', 'take', 'a', 'loan', 'out', 'of', 'it', ',', 'so', 'you', 'can', 'look', 'into', 'that', 'as', 'well', '.', '[SEP]']), (402437, ['[CLS]', 'understanding', 'sec', 'filing', '##s', '[SEP]', '&', 'gt', ';', 'the', 'base', 'value', 'from', 'infrastructure', 'is', 'derived', 'on', 'a', 'per', '-', 'capita', 'basis', '.', 'it', 'is', 'a', '\"', 'fixed', 'cost', '\"', 'as', 'opposed', 'to', 'a', 'variable', 'one', '.', 'in', 'other', 'words', ',', 'roads', 'are', 'just', 'as', 'useful', 'to', 'me', 'as', 'they', 'are', 'to', 'you', 'regardless', 'of', 'my', 'net', 'worth', '.', 'a1', ':', 'misleading', ':', 'infrastructure', 'is', 'useful', 'to', 'those', 'who', 'use', 'it', 'more', 'independently', 'of', 'classify', '##ing', 'it', 'as', '[', 'fixed', 'vs', 'variable', ']', '(', 'http', ':', '/', '/', 'en', '.', 'wikipedia', '.', 'org', '/', 'wi', '##ki', '/', 'fixed', '_', 'cost', ')', '.', 'take', 'the', 'faa', 'for', 'example', '.', 'the', 'poor', 'who', 'cannot', 'afford', 'a', 'plane', 'ticket', 'and', '/', 'or', 'order', 'things', 'via', 'next', '-', 'day', 'air', 'derive', 'very', 'little', 'benefit', 'from', 'the', 'faa', 'compared', 'to', 'a', 'person', 'who', 'owns', 'their', 'own', 'aircraft', 'and', 'can', 'fly', 'out', 'at', 'a', 'moments', 'notice', 'knowing', 'full', 'well', 'they', 'can', 'file', 'a', 'flight', 'plan', 'and', 'communicate', 'with', 'a', 'network', 'of', 'airports', 'to', 'ensure', 'their', 'plane', 'will', 'not', 'crash', 'into', 'any', 'other', 'jets', '.', '&', 'gt', ';', 'a', 'tank', ',', 'a', 'missile', ',', 'a', 'police', 'officer', 'protects', 'me', 'the', 'same', 'as', 'it', 'does', 'anyone', 'else', '.', 'a2', ':', 'but', ',', 'a', 'person', 'with', 'more', 'net', 'worth', 'has', 'more', 'to', 'lose', 'than', 'a', 'person', 'with', 'low', 'net', 'worth', '.', 'therefore', ',', 'even', 'independent', 'of', 'a1', 'above', ',', 'your', 'statement', 'is', 'false', '.', 'those', 'examples', 'protect', 'those', 'with', 'more', 'property', '/', 'net', '-', 'worth', '/', 'etc', 'more', '-', 'so', 'than', 'those', 'with', 'less', '.', '&', 'gt', ';', 'b', ')', 'as', 'a', 'percentage', 'of', 'income', ',', 'infrastructure', 'is', 'far', 'more', 'valuable', 'to', 'low', '-', 'income', 'individuals', 'than', 'high', '-', 'income', 'individuals', 'it', 'depends', 'on', 'the', 'infrastructure', ':', 'but', 'there', 'is', 'far', 'more', 'infrastructure', 'protecting', 'the', 'wealthy', 'than', 'the', 'poor', '.', 'your', 'example', 'is', 'the', 'stock', 'market', '.', 'why', 'should', 'the', 'vast', 'majority', 'of', 'people', 'pay', 'for', 'sec', 'and', 'rules', 'and', 'regulations', 'to', 'require', '/', 'enforce', 'honest', 'filing', '##s', 'when', 'they', 'cannot', 'afford', 'stock', '?', 'who', 'benefits', 'from', 'sec', 'infrastructure', '.', 'you', 'and', 'i', 'do', '.', 'value', 'to', 'poor', 'as', 'a', 'percentage', 'of', 'income', '=', '0', '%', '.', 'value', 'to', 'rich', '&', 'gt', ';', '0', '%', '.', 'q', '##ed', '.', 'your', 'roads', 'argument', 'as', 'an', 'example', 'of', 'poor', 'using', 'more', 'infrastructure', 'than', 'the', 'rich', 'is', 'a', 'bad', 'one', '.', 'the', 'poor', 'are', 'more', 'likely', 'to', 'take', 'public', 'transportation', 'and', '/', 'or', 'work', 'within', '5', 'miles', 'of', 'their', 'residence', '.', 'the', 'rich', 'are', 'more', 'likely', 'to', 'have', 'multiple', 'cars', ',', 'live', 'in', 'gate', '##d', 'areas', 'far', 'from', 'work', 'and', 'take', 'long', 'road', 'trips', '.', 'staying', 'at', 'home', 'to', 'work', 'is', 'a', 'function', 'of', 'more', 'than', 'just', 'owning', 'stock', '.', 'there', 'are', 'at', '-', 'home', '-', 'parents', ',', 'it', 'professionals', ',', 'programmers', ',', 'vo', '##ip', 'operators', ',', 'etc', ',', 'all', 'working', 'from', 'home', 'and', 'completely', 'independent', 'of', 'road', 'use', '.', '&', 'gt', ';', 'c', ')', 'the', 'activities', 'of', 'business', 'owners', 'generate', 'massive', 'tax', 'revenues', '.', 'these', 'far', 'out', '##weig', '##h', 'their', 'personal', 'utility', 'from', 'infrastructure', '.', 'c1', ':', '\"', 'personal', 'utility', '\"', 'you', 'are'])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EewC_SM1fjqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_docid_to_seq = load_pickle(path+'data-bert/test_docid_to_seq.pickle')\n",
        "test_docid_to_seq = load_pickle(path+'data-bert/test_docid_to_seq_512.pickle')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu7rnpVXPV3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_rank(model, test_set, qid_rel, max_seq_len):\n",
        "\n",
        "    qid_pred_rank = {}\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for i, seq in enumerate(tqdm(test_set)):\n",
        "        \n",
        "        qid, label, cands = seq[0], seq[1], seq[2]\n",
        "\n",
        "        cands_id = np.array(cands)\n",
        "\n",
        "        scores = []\n",
        "\n",
        "        for docid in cands:\n",
        "\n",
        "            seq_text = test_docid_to_seq[docid]\n",
        "\n",
        "            encoded_seq = tokenizer.convert_tokens_to_ids(seq_text)\n",
        "\n",
        "            input_ids = pad_seq(encoded_seq, max_seq_len)\n",
        "\n",
        "            att_mask = torch.tensor([[int(token_id > 0) for token_id in input_ids]]).to(device)\n",
        "            \n",
        "            input_ids = torch.tensor([input_ids]).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "            # Forward pass, calculate logit predictions\n",
        "                outputs = model(input_ids, token_type_ids=None, attention_mask=att_mask)\n",
        "\n",
        "            logits = outputs[0]\n",
        "\n",
        "            pred = torch.sigmoid(logits)\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            pred = pred.detach().cpu().numpy()\n",
        "\n",
        "            scores.append(pred[:,1][0])\n",
        "\n",
        "        # Get the indices of the sorted similarity scores\n",
        "        sorted_index = np.argsort(scores)[::-1]\n",
        "\n",
        "        # Get the docid from the sorted indices\n",
        "        ranked_ans = cands_id[sorted_index]\n",
        "\n",
        "        # Dict - key: qid, value: ranked list of docids\n",
        "        qid_pred_rank[qid] = ranked_ans\n",
        "\n",
        "    return qid_pred_rank\n",
        "    # MRR, average_ndcg, precision = evaluate(qid_pred_rank, qid_rel, k)\n",
        "\n",
        "    # return qid_pred_rank, MRR, average_ndcg, precision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOR-OM-qbb3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "toy_test_label = dict(itertools.islice(test_qid_rel.items(), 10))\n",
        "toy_test = test_set[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGa0KvT4cbbo",
        "colab_type": "code",
        "outputId": "22cc6c42-82cf-45c6-c388-e312c05038b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.load_state_dict(torch.load(path+'model/2_model-bert-512.pt'))\n",
        "\n",
        "qid_pred_rank = get_rank(model, toy_test, toy_test_label, max_seq_len=512)\n",
        "# qid_pred_rank = get_rank(model, test_set_full, test_qid_rel, max_seq_len=256)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [01:46<00:00, 10.63s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHjUlJszDAd7",
        "colab_type": "code",
        "outputId": "6b7dedae-ba15-45f5-814e-3e117f605a0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "k = 10\n",
        "\n",
        "num_q = len(toy_test)\n",
        "\n",
        "MRR, average_ndcg, precision = evaluate(qid_pred_rank, test_qid_rel, k)\n",
        "\n",
        "print(\"\\n\\nAverage nDCG@{} for {} queries: {}\\n\".format(k, num_q, average_ndcg))\n",
        "\n",
        "print(\"MRR@{} for {} queries: {}\\n\".format(k, num_q, MRR))\n",
        "\n",
        "print(\"Average Precision@{}: {}\".format(1, precision))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Average nDCG@10 for 10 queries: 0.7\n",
            "\n",
            "MRR@10 for 10 queries: 0.01951951951951952\n",
            "\n",
            "Average Precision@1: 0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcfbXb5eBcX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_pickle(path+'rank/2_bert_test_full.pickle', qid_pred_rank)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}