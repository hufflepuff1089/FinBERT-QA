{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinBERT-QA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e06df6be0a3a4b15bb17be728b8fb884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a54f8f8eb9b5498babeb18e54fb107d2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e9de99d131104ed2b7dd1621b42ed7bb",
              "IPY_MODEL_4f24f9823ab2464dbd9dce3bec3edf63"
            ]
          }
        },
        "a54f8f8eb9b5498babeb18e54fb107d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9de99d131104ed2b7dd1621b42ed7bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_20846c5a3480488684c0a9fc53c2042b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_17c1ad7179254acc81f6f034c9f30e44"
          }
        },
        "4f24f9823ab2464dbd9dce3bec3edf63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_76ada6839eff4d95ad187dd519605776",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 310kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5fde7cc9c7234593b721842230968051"
          }
        },
        "20846c5a3480488684c0a9fc53c2042b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "17c1ad7179254acc81f6f034c9f30e44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76ada6839eff4d95ad187dd519605776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5fde7cc9c7234593b721842230968051": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYTJmWOgraFa",
        "colab_type": "text"
      },
      "source": [
        "# **FinBERT-QA**\n",
        "As an alternative to running the scripts on the command line, this notebook shows the process of fine-tuning a pre-trained BERT model to the Opionated Financial Question and Answering (FiQA) dataset.\n",
        "\n",
        "The evaluation, prediction, and analysis of the FinBERT-QA model can be found after the fine-tuning process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBMhV22cZpDI",
        "colab_type": "code",
        "outputId": "d7f544c7-435f-403f-a89f-2089dae8564b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install pyserini==0.8.1.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\r\u001b[K     |▋                               | 10kB 25.2MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 861kB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 1.3MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 1.1MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 1.3MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 1.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92kB 1.3MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 409kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 450kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 460kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 501kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 532kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 542kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 552kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 573kB 1.4MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\r\u001b[K     |▍                               | 10kB 35.5MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 46.2MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30kB 56.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40kB 59.8MB/s eta 0:00:01\r\u001b[K     |██                              | 51kB 60.5MB/s eta 0:00:01\r\u001b[K     |██▎                             | 61kB 62.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 71kB 62.3MB/s eta 0:00:01\r\u001b[K     |███                             | 81kB 65.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 92kB 66.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 102kB 68.5MB/s eta 0:00:01\r\u001b[K     |████▏                           | 112kB 68.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 122kB 68.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 133kB 68.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 143kB 68.5MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 153kB 68.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 163kB 68.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 174kB 68.5MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 184kB 68.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 194kB 68.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 204kB 68.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 215kB 68.5MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 225kB 68.5MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 235kB 68.5MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 245kB 68.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 256kB 68.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 266kB 68.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 276kB 68.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 286kB 68.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 296kB 68.5MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 307kB 68.5MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 317kB 68.5MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 327kB 68.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 337kB 68.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 348kB 68.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 358kB 68.5MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 368kB 68.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 378kB 68.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 389kB 68.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 399kB 68.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 409kB 68.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 419kB 68.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 430kB 68.5MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 440kB 68.5MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 450kB 68.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 460kB 68.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 471kB 68.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 481kB 68.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 491kB 68.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 501kB 68.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 512kB 68.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 522kB 68.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 532kB 68.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 542kB 68.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 552kB 68.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 563kB 68.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 573kB 68.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 583kB 68.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 593kB 68.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 604kB 68.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 614kB 68.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 624kB 68.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 634kB 68.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 645kB 68.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 655kB 68.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 665kB 68.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 675kB 68.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 686kB 68.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 696kB 68.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 706kB 68.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 716kB 68.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 727kB 68.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 737kB 68.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 747kB 68.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 757kB 68.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 768kB 68.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 778kB 68.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 788kB 68.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 798kB 68.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 808kB 68.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 819kB 68.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 829kB 68.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 839kB 68.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 849kB 68.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 860kB 68.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 870kB 68.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 58.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.38)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 55.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.38 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.38)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=56f3db31b68b47b26c068cbc86810fbf97b64548502634a6c1b5f612777ba3d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.8.0\n",
            "Collecting pyserini==0.8.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/f4/45a9175211da4b7d4aed77af707eab938fc068d6124fc6673da748bc74bd/pyserini-0.8.1.0-py3-none-any.whl (57.7MB)\n",
            "\u001b[K     |████████████████████████████████| 57.7MB 55kB/s \n",
            "\u001b[?25hCollecting pyjnius\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/4f/e3d9f4bb53f7f1854f81a279c274c4ad8537e4d71117258515158403bc10/pyjnius-1.2.1-cp36-cp36m-manylinux2010_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 55.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from pyserini==0.8.1.0) (0.29.16)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from pyjnius->pyserini==0.8.1.0) (1.12.0)\n",
            "Installing collected packages: pyjnius, pyserini\n",
            "Successfully installed pyjnius-1.2.1 pyserini-0.8.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySXHdHsEUxNd",
        "colab_type": "code",
        "outputId": "282a36c6-d946-456f-bbb5-db36bc5e53a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "!git clone https://github.com/yuanbit/FinBERT-QA"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'FinBERT-QA'...\n",
            "remote: Enumerating objects: 38, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 947 (delta 17), reused 25 (delta 14), pack-reused 909\u001b[K\n",
            "Receiving objects: 100% (947/947), 230.67 MiB | 11.21 MiB/s, done.\n",
            "Resolving deltas: 100% (519/519), done.\n",
            "Checking out files: 100% (80/80), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdAFUpPyk-4v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3f52c88b-a16e-409a-eaaf-e490ef71175e"
      },
      "source": [
        "%cd FinBERT-QA/\n",
        "from src.utils import *\n",
        "from src.evaluate import *"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/FinBERT-QA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycQiTqG6ZcOv",
        "colab_type": "code",
        "outputId": "735f8498-0c0f-4e70-e91c-7668a5980c7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import json\n",
        "import os\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.nn.functional import softmax\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup, BertConfig\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "from pyserini.search import pysearch\n",
        "\n",
        "# Setting device on GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "print()\n",
        "\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Tesla P100-PCIE-16GB\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.0 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz-pwt46vIcX",
        "colab_type": "text"
      },
      "source": [
        "## **Configure hyperparameters and load data**\n",
        "\n",
        "**bert_model_name configuration:**\n",
        "\n",
        "1. 'bert-qa': uses a pre-trained BERT model fine-tuned on the MS Macro passage dataset of [Nogueira and Cho](https://github.com/nyu-dl/dl4marco-bert).\n",
        "2. 'finbert-domain': uses a further pre-trained BERT model of [Araci](https://github.com/ProsusAI/finBERT) on a large financial corpus\n",
        "3. 'finbert-task': uses a further pre-trained BERT model on the FiQA dataset\n",
        "4. 'bert-base': uses the 'bert-base-uncased' model from huggingface\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4KGOdhviDpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = {'bert_model_name': 'bert-qa',\n",
        "          'max_seq_len': 512,\n",
        "          'batch_size': 16,\n",
        "          'learning_rate': 3e-6,\n",
        "          'weight_decay': 0.01,\n",
        "          'n_epochs': 2,\n",
        "          'num_warmup_steps': 10000}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2YEBYUoZvfG",
        "colab_type": "code",
        "outputId": "a08aecdc-7cb6-4216-f318-77c01f5af643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "e06df6be0a3a4b15bb17be728b8fb884",
            "a54f8f8eb9b5498babeb18e54fb107d2",
            "e9de99d131104ed2b7dd1621b42ed7bb",
            "4f24f9823ab2464dbd9dce3bec3edf63",
            "20846c5a3480488684c0a9fc53c2042b",
            "17c1ad7179254acc81f6f034c9f30e44",
            "76ada6839eff4d95ad187dd519605776",
            "5fde7cc9c7234593b721842230968051"
          ]
        }
      },
      "source": [
        "# Dictionary mapping docid and qid to raw text\n",
        "docid_to_text = load_pickle('data/id_to_text/docid_to_text.pickle')\n",
        "qid_to_text = load_pickle('data/id_to_text/qid_to_text.pickle')\n",
        "\n",
        "# List of lists:\n",
        "# Each element is a list contraining [qid, list of pos docid, list of candidate docid]\n",
        "train_set = load_pickle('data/data_pickle/train_set_50.pickle')\n",
        "valid_set = load_pickle('data/data_pickle/valid_set_50.pickle')\n",
        "test_set = load_pickle('data/data_pickle/test_set_50.pickle')\n",
        "\n",
        "# Labels\n",
        "labels = load_pickle('data/data_pickle/labels.pickle')\n",
        "\n",
        "print(\"Number of questions in the training set: {}\".format(len(train_set)))\n",
        "print(\"Number of questions in the validation set: {}\".format(len(valid_set)))\n",
        "print(\"Number of questions in the test set: {}\".format(len(test_set)))\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('\\nLoading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of questions in the training set: 5676\n",
            "Number of questions in the validation set: 631\n",
            "Number of questions in the test set: 333\n",
            "\n",
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e06df6be0a3a4b15bb17be728b8fb884",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9_cmDMdmnGj",
        "colab_type": "text"
      },
      "source": [
        "## **Prepare data**\n",
        "Create the required inputs for fine-tuning and convert them to DataLoader objects to be trained in batches.\n",
        "\n",
        "**Required input data:**\n",
        "1. input_ids of concatenated question and answer sequences\n",
        "2. token_type_ids are segment ids incidiating if the index is part of a question or answer\n",
        "3. att_masks are ids indicating if the index is part of the sequence or padding\n",
        "4. labels indicating if a QA pair is positive or negative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-hWS0v0sx7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_input_data(dataset, max_seq_len):\n",
        "    \"\"\"Creates input parameters for training and validation.\n",
        "\n",
        "    Returns:\n",
        "        input_ids: List of lists\n",
        "                Each element contains a list of padded/truncated numericalized\n",
        "                tokens of the sequences including [CLS] and [SEP] tokens\n",
        "                e.g. [[101, 2054, 2003, 102, 2449, 1029, 102], ...]\n",
        "        token_type_ids: List of lists\n",
        "                Each element contains a list of segment token indices to\n",
        "                indicate first (question) and second (answer) parts of the inputs.\n",
        "                0 corresponds to a question token, 1 corresponds an answer token\n",
        "                e.g. [[0, 0, 0, 0, 1, 1, 1], ...]\n",
        "        att_masks: List of lists\n",
        "                Each element contains a list of mask values to avoid\n",
        "                performing attention on padding token indices.\n",
        "                1 for tokens that are NOT MASKED, 0 for MASKED tokens.\n",
        "                e.g. [[1, 1, 1, 1, 1, 1, 1], ...]\n",
        "        labels: List of 1's and 0's incidating relevacy of answer\n",
        "    -----------------\n",
        "    Arguements:\n",
        "        dataset: List of lists in the form of [qid, [pos ans], [ans cands]]\n",
        "    \"\"\"\n",
        "    input_ids = []\n",
        "    token_type_ids = []\n",
        "    att_masks = []\n",
        "    labels = []\n",
        "\n",
        "    for i, seq in enumerate(tqdm(dataset)):\n",
        "        qid, ans_labels, cands = seq[0], seq[1], seq[2]\n",
        "        # Map question id to text\n",
        "        q_text = qid_to_text[qid]\n",
        "        # For each answer in the candidates\n",
        "        for docid in cands:\n",
        "            # Map the docid to text\n",
        "            ans_text = docid_to_text[docid]\n",
        "            # Encode the sequence using BERT tokenizer\n",
        "            encoded_seq = tokenizer.encode_plus(q_text, ans_text,\n",
        "                                                max_length=max_seq_len,\n",
        "                                                pad_to_max_length=True,\n",
        "                                                return_token_type_ids=True,\n",
        "                                                return_attention_mask = True)\n",
        "            # Get parameters\n",
        "            input_id = encoded_seq['input_ids']\n",
        "            token_type_id = encoded_seq['token_type_ids']\n",
        "            att_mask = encoded_seq['attention_mask']\n",
        "\n",
        "            # If an answer is in the list of relevant answers assign\n",
        "            # positive label\n",
        "            if docid in ans_labels:\n",
        "                label = 1\n",
        "            else:\n",
        "                label = 0\n",
        "\n",
        "            # Each parameter list has the length of the max_seq_len\n",
        "            assert len(input_id) == max_seq_len, \"Input id dimension incorrect!\"\n",
        "            assert len(token_type_id) == max_seq_len, \"Token type id dimension incorrect!\"\n",
        "            assert len(att_mask) == max_seq_len, \"Attention mask dimension incorrect!\"\n",
        "\n",
        "            input_ids.append(input_id)\n",
        "            token_type_ids.append(token_type_id)\n",
        "            att_masks.append(att_mask)\n",
        "            labels.append(label)\n",
        "\n",
        "    return input_ids, token_type_ids, att_masks, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX3dEiY-MzxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dataloader(dataset, type, max_seq_len, batch_size):\n",
        "    \"\"\"Creates train and validation DataLoaders with input_ids,\n",
        "    token_type_ids, att_masks, and labels\n",
        "\n",
        "    Returns:\n",
        "        train_dataloader: DataLoader object\n",
        "        validation_dataloader: DataLoader object\n",
        "\n",
        "    -----------------\n",
        "    Arguements:\n",
        "        dataset: List of lists in the form of [qid, [pos ans], [ans cands]]\n",
        "        type: str - 'train' or 'validation'\n",
        "        max_seq_len: int\n",
        "        batch_size: int\n",
        "    \"\"\"\n",
        "    input_id, token_type_id, \\\n",
        "    att_mask, label = get_input_data(dataset, max_seq_len)\n",
        "\n",
        "    # Convert all inputs to torch tensors\n",
        "    input_ids = torch.tensor(input_id)\n",
        "    token_type_ids = torch.tensor(token_type_id)\n",
        "    att_masks = torch.tensor(att_mask)\n",
        "    labels = torch.tensor(label)\n",
        "\n",
        "    # Create the DataLoader for our training set.\n",
        "    data = TensorDataset(input_ids, token_type_ids, att_masks, labels)\n",
        "    if type == \"train\":\n",
        "        sampler = RandomSampler(data)\n",
        "    else:\n",
        "        sampler = SequentialSampler(data)\n",
        "    dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n",
        "    \n",
        "    return dataloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhPBExB2bjG-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "8a1b1309-b1a8-41bc-ffdd-019f6f20a2d7"
      },
      "source": [
        "# Get dataloaders\n",
        "train_dataloader = get_dataloader(train_set, 'train', \n",
        "                                  config['max_seq_len'], \n",
        "                                  config['batch_size'])\n",
        "validation_dataloader = get_dataloader(valid_set, 'validation', \n",
        "                                       config['max_seq_len'], \n",
        "                                       config['batch_size'])\n",
        "\n",
        "print(\"\\n\\nSize of the training DataLoader: {}\".format(len(train_dataloader)))\n",
        "print(\"Size of the validation DataLoader: {}\".format(len(validation_dataloader)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5676/5676 [24:24<00:00,  3.88it/s]\n",
            "100%|██████████| 631/631 [02:42<00:00,  3.89it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Size of the training DataLoader: 17738\n",
            "Size of the validation DataLoader: 1972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zaovfEtm7Mf",
        "colab_type": "text"
      },
      "source": [
        "# **Model**\n",
        "Initiate a pre-trained BERT model with a single linear classification layer on top."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ieelr1DenCjH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "9c2cf413-fa21-4eb4-929c-76fdeebe4e09"
      },
      "source": [
        "# Download pre-trained BERT model\n",
        "# The model was converted from TensorFlow to PyTorch format\n",
        "get_model(config['bert_model_name'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading bert-qa model...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 406M/406M [00:07<00:00, 51.2MiB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBGukeI_cCPy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "77d161f0-a81b-48b6-fa2c-2aa966e40ee7"
      },
      "source": [
        "if config['bert_model_name'] == 'bert-base-uncased':\n",
        "    model_path = config['bert_model_name']\n",
        "else:\n",
        "    model_path = \"model/\" + config['bert_model_name']\n",
        "\n",
        "# Load BertForSequenceClassification - pretrained BERT model \n",
        "# with a single linear classification layer on top\n",
        "model = BertForSequenceClassification.from_pretrained(model_path, cache_dir=None, num_labels=2)\n",
        "\n",
        "model.to(device)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPQfVrBHnaIO",
        "colab_type": "text"
      },
      "source": [
        "# **Training and Validation Methods**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diWEgRaLGoyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(preds, labels):\n",
        "    \"\"\"Compute the accuracy of binary predictions.\n",
        "\n",
        "    Returns:\n",
        "        accuracy: float\n",
        "    -----------------\n",
        "    Arguments:\n",
        "        preds: Numpy list with two columns of probabilities for each label\n",
        "        labels: List of labels\n",
        "    \"\"\"\n",
        "    # Get the label (column) with the higher probability\n",
        "    predictions = np.argmax(preds, axis=1).flatten()\n",
        "    labels = labels.flatten()\n",
        "    # Compute accuracy\n",
        "    accuracy = np.sum(predictions == labels) / len(labels)\n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9kxwJskHG1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_dataloader, optimizer, scheduler):\n",
        "    \"\"\"Trains the model and returns the average loss and accuracy.\n",
        "\n",
        "    Returns:\n",
        "        avg_loss: Float\n",
        "        avg_acc: Float\n",
        "    ----------\n",
        "    Arguements:\n",
        "        model: Torch model\n",
        "        train_dataloader: DataLoader object\n",
        "        optimizer: Optimizer object\n",
        "        scheduler: Scheduler object\n",
        "    \"\"\"\n",
        "    # Cumulated Training loss and accuracy\n",
        "    total_loss = 0\n",
        "    train_accuracy = 0\n",
        "    # Track the number of steps\n",
        "    num_steps = 0\n",
        "    # Set model in train mode\n",
        "    model.train()\n",
        "    # For each batch of training data\n",
        "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
        "        # Get tensors and move to gpu\n",
        "        # batch contains four PyTorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: token_type_ids\n",
        "        #   [2]: attention masks\n",
        "        #   [3]: labels\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_token_type_ids = batch[1].to(device)\n",
        "        b_input_mask = batch[2].to(device)\n",
        "        b_labels = batch[3].to(device)\n",
        "\n",
        "        # Zero the gradients\n",
        "        model.zero_grad()\n",
        "        # Forward pass: the model will return the loss and the logits\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids = b_token_type_ids,\n",
        "                        attention_mask = b_input_mask,\n",
        "                        labels = b_labels)\n",
        "\n",
        "        # Get loss and predictions\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for a batch\n",
        "        tmp_accuracy = get_accuracy(logits, label_ids)\n",
        "\n",
        "        # Accumulate the total accuracy.\n",
        "        train_accuracy += tmp_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        num_steps += 1\n",
        "\n",
        "        # Accumulate the training loss over all of the batches\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    avg_acc = train_accuracy/num_steps\n",
        "\n",
        "    return avg_loss, avg_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iCcUYUvb6-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(model, validation_dataloader):\n",
        "    \"\"\"Validates the model and returns the average loss and accuracy.\n",
        "\n",
        "    Returns:\n",
        "        avg_loss: Float\n",
        "        avg_acc: Float\n",
        "    ----------\n",
        "    Arguements:\n",
        "        model: Torch model\n",
        "        validation_dataloader: DataLoader object\n",
        "    \"\"\"\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "    # Cumulated Training loss and accuracy\n",
        "    total_loss = 0\n",
        "    eval_accuracy = 0\n",
        "    # Track the number of steps\n",
        "    num_steps = 0\n",
        "\n",
        "    # For each batch of the validation data\n",
        "    for batch in tqdm(validation_dataloader):\n",
        "        # Move tensors from batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        # Unpack the inputs from the dataloader\n",
        "        b_input_ids, b_token_type_ids, b_input_masks, b_labels = batch\n",
        "        # Don't to compute or store gradients\n",
        "        with torch.no_grad():\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids = b_token_type_ids,\n",
        "                            attention_mask = b_input_masks,\n",
        "                            labels= b_labels)\n",
        "        # Get loss and logits\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = get_accuracy(logits, label_ids)\n",
        "\n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of steps\n",
        "        num_steps += 1\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Calculate loss and accuracy\n",
        "    avg_loss = total_loss / len(validation_dataloader)\n",
        "    avg_acc = eval_accuracy/num_steps\n",
        "\n",
        "    return avg_loss, avg_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z2f40LmnmJy",
        "colab_type": "text"
      },
      "source": [
        "# **Fine-tune FinBERT-QA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6lI80kbTo-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(), \n",
        "                  lr = config['learning_rate'], \n",
        "                  weight_decay = config['weight_decay'])\n",
        "\n",
        "n_epochs = config['n_epochs']\n",
        "\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * n_epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = config['num_warmup_steps'],\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdWsesbTVMt0",
        "colab_type": "code",
        "outputId": "94475c1f-08f0-4017-c923-6593830f9e2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Train and validate the model and print the average loss and accuracy.\n",
        "\n",
        "# Lowest validation lost\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # Evaluate training loss\n",
        "    train_loss, train_acc = train(model, train_dataloader, optimizer, scheduler)\n",
        "    # Evaluate validation loss\n",
        "    valid_loss, valid_acc = validate(model, validation_dataloader)\n",
        "    # At each epoch, if the validation loss is the best\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'model/' + str(epoch+1)+ '_finbert-qa.pt')\n",
        "\n",
        "    print(\"\\n\\n Epoch {}:\".format(epoch+1))\n",
        "    print(\"\\t Train Loss: {} | Train Accuracy: {}%\".format(round(train_loss, 3), round(train_acc*100, 2)))\n",
        "    print(\"\\t Validation Loss: {} | Validation Accuracy: {}%\\n\".format(round(valid_loss, 3), round(valid_acc*100, 2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 51%|█████     | 8998/17738 [2:09:54<2:06:04,  1.16it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3Qppb1-nvRg",
        "colab_type": "text"
      },
      "source": [
        "# **Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6npVgMDNewIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, q_text, cands, max_seq_len):\n",
        "    \"\"\"Re-ranks the candidates answers for each question.\n",
        "\n",
        "    Returns:\n",
        "        ranked_ans: list of re-ranked candidate docids\n",
        "        sorted_scores: list of relevancy scores of the answers\n",
        "    -------------------\n",
        "    Arguments:\n",
        "        model - PyTorch model\n",
        "        q_text - str - query\n",
        "        cands -List of retrieved candidate docids\n",
        "        max_seq_len - int\n",
        "    \"\"\"\n",
        "    # Convert list to numpy array\n",
        "    cands_id = np.array(cands)\n",
        "    # Empty list for the probability scores of relevancy\n",
        "    scores = []\n",
        "    # For each answer in the candidates\n",
        "    for docid in cands:\n",
        "        # Map the docid to text\n",
        "        ans_text = docid_to_text[docid]\n",
        "        # Create inputs for the model\n",
        "        encoded_seq = self.tokenizer.encode_plus(q_text, ans_text,\n",
        "                                            max_length=max_seq_len,\n",
        "                                            pad_to_max_length=True,\n",
        "                                            return_token_type_ids=True,\n",
        "                                            return_attention_mask = True)\n",
        "\n",
        "        # Numericalized, padded, clipped seq with special tokens\n",
        "        input_ids = torch.tensor([encoded_seq['input_ids']]).to(device)\n",
        "        # Specify question seq and answer seq\n",
        "        token_type_ids = torch.tensor([encoded_seq['token_type_ids']]).to(device)\n",
        "        # Sepecify which position is part of the seq which is padded\n",
        "        att_mask = torch.tensor([encoded_seq['attention_mask']]).to(device)\n",
        "        # Don't calculate gradients\n",
        "        with torch.no_grad():\n",
        "            # Forward pass, calculate logit predictions for each QA pair\n",
        "            outputs = model(input_ids, token_type_ids=token_type_ids, attention_mask=att_mask)\n",
        "        # Get the predictions\n",
        "        logits = outputs[0]\n",
        "        # Apply activation function\n",
        "        pred = softmax(logits, dim=1)\n",
        "        # Move logits and labels to CPU\n",
        "        pred = pred.detach().cpu().numpy()\n",
        "        # Append relevant scores to list (where label = 1)\n",
        "        scores.append(pred[:,1][0])\n",
        "        # Get the indices of the sorted similarity scores\n",
        "        sorted_index = np.argsort(scores)[::-1]\n",
        "        # Get the list of docid from the sorted indices\n",
        "        ranked_ans = list(cands_id[sorted_index])\n",
        "        sorted_scores = list(np.around(sorted(scores, reverse=True),decimals=3))\n",
        "\n",
        "    return ranked_ans, sorted_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRSvaM8BEvH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_rank(model, test_set, max_seq_len):\n",
        "    \"\"\"Re-ranks the candidates answers for each question.\n",
        "\n",
        "    Returns:\n",
        "        qid_pred_rank: Dictionary\n",
        "            key - qid\n",
        "            value - list of re-ranked candidates\n",
        "    -------------------\n",
        "    Arguments:\n",
        "        model - PyTorch model\n",
        "        test_set  List of lists\n",
        "        max_seq_len - int\n",
        "    \"\"\"\n",
        "    # Initiate empty dictionary\n",
        "    qid_pred_rank = {}\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "    # For each element in the test set\n",
        "    for i, seq in enumerate(tqdm(test_set)):\n",
        "        # question id, list of rel answers, list of candidates\n",
        "        qid, label, cands = seq[0], seq[1], seq[2]\n",
        "        # Map question id to text\n",
        "        q_text = qid_to_text[qid]\n",
        "\n",
        "        # List of re-ranked docids and the corresponding probabilities\n",
        "        ranked_ans, sorted_scores = predict(model, q_text, cands, max_seq_len)\n",
        "\n",
        "        # Dict - key: qid, value: ranked list of docids\n",
        "        qid_pred_rank[qid] = ranked_ans\n",
        "\n",
        "    return qid_pred_rank"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCSL8fW1y6Xn",
        "colab_type": "text"
      },
      "source": [
        "**get_trained_model()** downloads a fine-tuned model - the available model_name are:\n",
        "1. finbert-qa: 'bert-qa' fine-tuned on FiQA\n",
        "2. finbert-domain: 'finbert-domain' fine-tuned on FiQA\n",
        "3. finbert-task: 'finberr-task' fine-tuned on FiQA\n",
        "4. bert-pointwise: 'bert-base-uncase' fine-tuned on FiQA using the cross-entropy loss\n",
        "5. bert-pairwise: 'bert-base-uncase' fine-tuned on FiQA using a pairwise loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ5dr2hKo1X3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = 'finbert-qa'\n",
        "checkpoint = get_trained_model(model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2dgKDgyow98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trained_model_path = \"model/trained/\" + model_name + \"/\" + checkpoint\n",
        "\n",
        "# # Load model\n",
        "# model.load_state_dict(torch.load(trained_model_path))\n",
        "\n",
        "# # Get rank\n",
        "# qid_pred_rank = get_rank(model, test_set, config['max_seq_len'])\n",
        "\n",
        "# k = 10\n",
        "# num_q = len(test_set)\n",
        "\n",
        "# # Evaluate\n",
        "# MRR, average_ndcg, precision, rank_pos = evaluate(qid_pred_rank, labels, k)\n",
        "\n",
        "# print(\"Average nDCG@{0} for {1} queries: {2:.3f}\".format(k, num_q, average_ndcg))\n",
        "# print(\"MRR@{0} for {1} queries: {2:.3f}\".format(k, num_q, MRR))\n",
        "# print(\"Average Precision@1 for {0} queries: {1:.3f}\".format(num_q, precision))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQEhAYG2pBDl",
        "colab_type": "text"
      },
      "source": [
        "# **Predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJhoyHY5pCpg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_rel(labels, cands):\n",
        "    \"\"\"Get relevant positions of the hits.\n",
        "\n",
        "    Returns: List of 0's and 1's incidating a relevant answer\n",
        "    -------------------\n",
        "    Arguments:\n",
        "        labels: List of relevant docids\n",
        "        cands: List of candidate docids\n",
        "    \"\"\"\n",
        "    rel = []\n",
        "    for cand in cands:\n",
        "        if cand in labels:\n",
        "            rel.append(1)\n",
        "        else:\n",
        "            rel.append(0)\n",
        "\n",
        "    return rel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdaBYwZ0pI0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FIQA_INDEX = \"retriever/lucene-index-fiqa\"\n",
        "\n",
        "searcher = pysearch.SimpleSearcher(FIQA_INDEX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiVoQXV-pODJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# seq = test_set[91]\n",
        "# qid, label, cands = seq[0], seq[1], seq[2]\n",
        "# q_text = qid_to_text[qid]\n",
        "# query = q_text\n",
        "# print(query)\n",
        "# # query = \"Which investments are the best?\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvVmOJwVpO8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hits = searcher.search(query, k=50)\n",
        "# self.cands = []\n",
        "\n",
        "# for i in range(0, len(hits)):\n",
        "#     cands.append(int(hits[i].docid))\n",
        "\n",
        "# # Load model\n",
        "# model.load_state_dict(torch.load(trained_model_path))\n",
        "# model.eval()\n",
        "\n",
        "# rank, scores = predict(model, query, cands)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS0KmGvwpW15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# k = 5\n",
        "\n",
        "# print(\"Question: \\n\\t{}\\n\".format(query))\n",
        "# print(\"Top-{} Answers: \\n\".format(k))\n",
        "# for i in range(0, 10):\n",
        "#     print(\"{}.\\t{}\\n\".format(i+1, docid_to_text[rank[i]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdNPwLAvpZGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cand_rel = get_rel(label, cands)\n",
        "# print(\"Retriever: \\n\\t Ranking: {}\\n\\n\\t {}\".format(cands[:10], cand_rel[:10]))\n",
        "# pred_rel = get_rel(label, rank)\n",
        "# print(\"Re-ranker: \\n\\t Ranking: {}\\n\\n\\t Scores: {}\\n\\n\\t {}\".format(rank[:10], scores[:10], pred_rel[:10]))\n",
        "# print(\"Label: \\n\\t{}\".format(label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhdBEnhgpa_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"Question: \\n\\t{}\\n\".format(query))\n",
        "# print(\"Answer Re-ranker\\n\")\n",
        "# print(\"Answer: \\n\\t{}\\n\".format(docid_to_text[rank[0]]))\n",
        "# print(\"Answer Retriever\\n\")\n",
        "# print(\"Answer: \\n\\t{}\\n\".format(docid_to_text[cands[0]]))\n",
        "# print(\"label: \\n\\t{}\".format(docid_to_text[label[1]]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}