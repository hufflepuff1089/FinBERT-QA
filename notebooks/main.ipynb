{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5bPcwwy6MjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r fiqa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohZogJhu48bm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "9c103684-60a5-4b4d-898d-dde2f1c34ead"
      },
      "source": [
        "!git clone https://github.com/yuanbit/fiqa.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fiqa'...\n",
            "remote: Enumerating objects: 42, done.\u001b[K\n",
            "remote: Counting objects:   2% (1/42)\u001b[K\rremote: Counting objects:   4% (2/42)\u001b[K\rremote: Counting objects:   7% (3/42)\u001b[K\rremote: Counting objects:   9% (4/42)\u001b[K\rremote: Counting objects:  11% (5/42)\u001b[K\rremote: Counting objects:  14% (6/42)\u001b[K\rremote: Counting objects:  16% (7/42)\u001b[K\rremote: Counting objects:  19% (8/42)\u001b[K\rremote: Counting objects:  21% (9/42)\u001b[K\rremote: Counting objects:  23% (10/42)\u001b[K\rremote: Counting objects:  26% (11/42)\u001b[K\rremote: Counting objects:  28% (12/42)\u001b[K\rremote: Counting objects:  30% (13/42)\u001b[K\rremote: Counting objects:  33% (14/42)\u001b[K\rremote: Counting objects:  35% (15/42)\u001b[K\rremote: Counting objects:  38% (16/42)\u001b[K\rremote: Counting objects:  40% (17/42)\u001b[K\rremote: Counting objects:  42% (18/42)\u001b[K\rremote: Counting objects:  45% (19/42)\u001b[K\rremote: Counting objects:  47% (20/42)\u001b[K\rremote: Counting objects:  50% (21/42)\u001b[K\rremote: Counting objects:  52% (22/42)\u001b[K\rremote: Counting objects:  54% (23/42)\u001b[K\rremote: Counting objects:  57% (24/42)\u001b[K\rremote: Counting objects:  59% (25/42)\u001b[K\rremote: Counting objects:  61% (26/42)\u001b[K\rremote: Counting objects:  64% (27/42)\u001b[K\rremote: Counting objects:  66% (28/42)\u001b[K\rremote: Counting objects:  69% (29/42)\u001b[K\rremote: Counting objects:  71% (30/42)\u001b[K\rremote: Counting objects:  73% (31/42)\u001b[K\rremote: Counting objects:  76% (32/42)\u001b[K\rremote: Counting objects:  78% (33/42)\u001b[K\rremote: Counting objects:  80% (34/42)\u001b[K\rremote: Counting objects:  83% (35/42)\u001b[K\rremote: Counting objects:  85% (36/42)\u001b[K\rremote: Counting objects:  88% (37/42)\u001b[K\rremote: Counting objects:  90% (38/42)\u001b[K\rremote: Counting objects:  92% (39/42)\u001b[K\rremote: Counting objects:  95% (40/42)\u001b[K\rremote: Counting objects:  97% (41/42)\u001b[K\rremote: Counting objects: 100% (42/42)\u001b[K\rremote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 416 (delta 21), reused 28 (delta 12), pack-reused 374\u001b[K\n",
            "Receiving objects: 100% (416/416), 176.73 MiB | 23.80 MiB/s, done.\n",
            "Resolving deltas: 100% (169/169), done.\n",
            "Checking out files: 100% (58/58), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEWIhdFr5GET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fiqa.src.qa_lstm import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grqzHCRx6mBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "train_set = load_pickle('fiqa/data/data_50/train_set_50.pickle')\n",
        "valid_set = load_pickle('fiqa/data/data_50/valid_set_50.pickle')\n",
        "\n",
        "vocab = load_pickle('fiqa/data/qa_lstm_tokenizer/word2index.pickle')\n",
        "qid_to_tokenized_text = load_pickle('fiqa/data/qa_lstm_tokenizer/qid_to_tokenized_text.pickle')\n",
        "docid_to_tokenized_text = load_pickle('fiqa/data/qa_lstm_tokenizer/docid_to_tokenized_text.pickle')\n",
        "\n",
        "config = {\n",
        "    'model_type': \"qa_lstm\",\n",
        "    'emb_dim': 100,\n",
        "    'hidden_size': 256,\n",
        "    'dropout': 0.2,\n",
        "    'max_seq_len': 512,\n",
        "    'batch_size': 64,\n",
        "    'n_epochs': 6,\n",
        "    'learning_rate': 0.001,\n",
        "    'device': device,\n",
        "    'vocab': vocab,\n",
        "    'qid_to_tokenized_text': qid_to_tokenized_text,\n",
        "    'docid_to_tokenized_text': docid_to_tokenized_text,\n",
        "    'train_set': train_set,\n",
        "    'valid_set': valid_set\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ziw3IyB7DoL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_model(config)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}