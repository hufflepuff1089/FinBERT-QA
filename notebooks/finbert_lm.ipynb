{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finbert-lm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYQ-PmL2oGEF",
        "colab_type": "code",
        "outputId": "7487a434-9589-445d-fb7d-5df664334752",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install tokenizers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.6/dist-packages (0.5.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDmaizerpBnR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import pickle\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from itertools import islice\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "from tokenizers.processors import BertProcessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKOaV8srokFo",
        "colab_type": "code",
        "outputId": "1829182e-61a6-4b2e-af79-db4de6e54597",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "# Setting device on GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "print()\n",
        "\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Set the random seed manually for reproducibility.\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "path = \"drive/My Drive/FiQA/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Tesla K80\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.0 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOv_l1hIoqtK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "collection = pd.read_csv(\"/content/drive/My Drive/Thesis/data/retrieval/collection_cleaned.tsv\", sep=\"\\t\", header=None)\n",
        "collection = collection.rename(columns={0: 'docid', 1: 'doc'})\n",
        "\n",
        "def load_questions(path):\n",
        "    \"\"\"\n",
        "    Returns a dataframe of cols: qid, question\n",
        "    \"\"\"\n",
        "    # Question ID and Question text\n",
        "    query_df = pd.read_csv(path, sep=\"\\t\")\n",
        "    queries = query_df[['qid', 'question']]\n",
        "\n",
        "    return queries\n",
        "\n",
        "queries = load_questions(path + \"FiQA_train_question_final.tsv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF8OzCLfps7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def take(n, iterable):\n",
        "    \"Return first n items of the iterable as a list\"\n",
        "    return list(islice(iterable, n))\n",
        "\n",
        "def remove_empty(test_set):\n",
        "    for index, row in enumerate(test_set):\n",
        "        for doc in row[1]:\n",
        "            if doc in empty_docs:\n",
        "                del test_set[index]\n",
        "    return test_set\n",
        "\n",
        "def load_pickle(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "def save_pickle(path, data):\n",
        "    with open(path, 'wb') as handle:\n",
        "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4-4w4xowyM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Question to question text\n",
        "qid_to_text = {}\n",
        "\n",
        "for index, row in queries.iterrows():\n",
        "    qid_to_text[row['qid']] = row['question']\n",
        "\n",
        "docid_to_text = {}\n",
        "\n",
        "for index, row in collection.iterrows():\n",
        "    docid_to_text[row['docid']] = row['doc']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGEM1v2hw5ZO",
        "colab_type": "code",
        "outputId": "8c757cdd-7d48-4096-ce18-8572fa2ca6ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "take(5, qid_to_text.items())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 'What is considered a business expense on a business trip?'),\n",
              " (1, 'Claiming business expenses for a business with no income'),\n",
              " (2,\n",
              "  'Transferring money from One business checking to another business checking'),\n",
              " (3,\n",
              "  'Having a separate bank account for business/investing, but not a “business account?”'),\n",
              " (4,\n",
              "  'Business Expense - Car Insurance Deductible For Accident That Occurred During a Business Trip')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpYSa7niuVR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "empty_docs = load_pickle(path+'empty_docs.pickle')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AisyaywRqjI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv(path+\"FiQA_train_question_doc_final.tsv\", sep=\"\\t\")\n",
        "dataset = dataset[[\"qid\", \"docid\"]]\n",
        "dataset = dataset[~dataset['docid'].isin(empty_docs)]\n",
        "dataset['question'] = dataset['qid'].apply(lambda x: qid_to_text[x])\n",
        "dataset['answer'] = dataset['docid'].apply(lambda x: docid_to_text[x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTXyvrmTxi41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_ques_token(string):\n",
        "    question = string + \" [SEP] \"\n",
        "\n",
        "    return question"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_VqMaAHxxLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['question'] = dataset['question'].apply(add_ques_token)\n",
        "dataset['seq'] = dataset['question'] + dataset['answer']\n",
        "dataset = dataset[['seq']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebyvFoD3yPat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['seq'] = dataset['question'] + dataset['answer']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTElO87wynEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataset[['seq']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGtgycxa3rCk",
        "colab_type": "code",
        "outputId": "f1383002-9f64-48ef-eac0-0a3b8388001a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "test = dataset.at[17081, \"seq\"]\n",
        "\n",
        "test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Is it wise to switch investment strategy frequently? [SEP] My super fund and I would say many other funds give you one free switch of strategies per year.  Some suggest you should change from high growth option to a more balance option once you are say about 10 to 15 years from retirement, and then change to a more capital guaranteed option a few years from retirement. This is a more passive approach and has benefits as well as disadvantages. The benefit is that there is not much work involved, you just change your investment option based on your life stage, 2 to 3 times during your lifetime. This allows you to take more risk when you are young to aim for higher returns, take a balanced approach with moderate risk and returns during the middle part of your working life, and take less risk with lower returns (above inflation) during the latter part of your working life. A possible disadvantage of this strategy is you may be in the higher risk/ higher growth option during a market correction and then change to a more balanced option just when the market starts to pick up again. So your funds will be hit with large losses whilst the market is in retreat and just when things look to be getting better you change to a more balanced portfolio and miss out on the big gains. A second more active approach would be to track the market and change investment option as the market changes. One approach which shouldn't take much time is to track the index such as the ASX200 (if you investment option is mainly invested in the Australian stock market) with a 200 day Simple Moving Average (SMA). The concept is that if the index crosses above the 200 day SMA the market is bullish and if it crosses below it is bearish. See the chart below:  This strategy will work well when the market is trending up or down but not very well when the market is going sideways, as you will be changing from aggressive to balanced and back too often. Possibly a more appropriate option would be a combination of the two. Use the first passive approach to change investment option from aggressive to balanced to capital guaranteed with your life stages, however use the second active approach to time the change. For example, if you were say in your late 40s now and were looking to change from aggressive to balanced in the near future, you could wait until the ASX200 crosses below the 200 day SMA before making the change. This way you could capture the majority of the uptrend (which could go on for years) before changing from the high growth/aggressive option to the balanced option. If you where after more control over your superannuation assets another option open to you is to start a SMSF, however I would recommend having at least $300K to $400K in assets before starting a SMSF, or else the annual costs would be too high as a percentage of your total super assets.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBRPqffDzISA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "\n",
        "dataset.to_csv(path+'bert-lm/data.txt',index=False,header=False, sep=\"\\t\", quoting=csv.QUOTE_NONE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaNMAvRG1IRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "paths = [str(x) for x in Path(path+\"bert-lm/\").glob(\"**/*.txt\")]\n",
        "\n",
        "# Initialize a tokenizer\n",
        "tokenizer = BertWordPieceTokenizer()\n",
        "\n",
        "# Customize training\n",
        "tokenizer.train(files=paths, vocab_size=52_000, min_frequency=1, special_tokens=[\n",
        "    \"[UNK]\",\n",
        "    \"[SEP]\",\n",
        "    \"[CLS]\",\n",
        "    \"[MASK]\",\n",
        "    \"[PAD]\",\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3xPex8kPD2I",
        "colab_type": "code",
        "outputId": "93092911-846a-4fd1-e910-bde12eb9c36f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tokenizer.save(path+\"/bert-lm/tokenizer\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['drive/My Drive/FiQA//bert-lm/tokenizer/vocab.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OQOumhV3d6I",
        "colab_type": "code",
        "outputId": "dbd05747-caae-490c-b86d-8ff4dcdeed03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tokenizer = BertWordPieceTokenizer(path+\"/bert-lm/tokenizer/vocab.txt\")\n",
        "tokenizer._tokenizer.post_processor = BertProcessing(\n",
        "    (\"[SEP]\", tokenizer.token_to_id(\"[CLS]\")),\n",
        "    (\"[CLS]\", tokenizer.token_to_id(\"[SEP]\")),\n",
        ")\n",
        "tokenizer.enable_truncation(max_length=512)\n",
        "\n",
        "# Save files to disk\n",
        "tokenizer.save(path+\"bert-lm\", \"finbert-lm\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['drive/My Drive/FiQA/bert-lm/finbert-lm-vocab.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xVB-DKNPRgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = \"Is it wise to switch investment strategy frequently? [SEP] My super fund and I would say many other funds give you one free switch of strategies per year.  Some suggest you should change from high growth option to a more balance option once you are say about 10 to 15 years from retirement, and then change to a more capital guaranteed option a few years from retirement. This is a more passive approach and has benefits as well as disadvantages. The benefit is that there is not much work involved, you just change your investment option based on your life stage, 2 to 3 times during your lifetime. This allows you to take more risk when you are young to aim for higher returns, take a balanced approach with moderate risk and returns during the middle part of your working life, and take less risk with lower returns (above inflation) during the latter part of your working life. A possible disadvantage of this strategy is you may be in the higher risk/ higher growth option during a market correction and then change to a more balanced option just when the market starts to pick up again. So your funds will be hit with large losses whilst the market is in retreat and just when things look to be getting better you change to a more balanced portfolio and miss out on the big gains. A second more active approach would be to track the market and change investment option as the market changes. One approach which shouldn't take much time is to track the index such as the ASX200 (if you investment option is mainly invested in the Australian stock market) with a 200 day Simple Moving Average (SMA). The concept is that if the index crosses above the 200 day SMA the market is bullish and if it crosses below it is bearish. See the chart below:  This strategy will work well when the market is trending up or down but not very well when the market is going sideways, as you will be changing from aggressive to balanced and back too often. Possibly a more appropriate option would be a combination of the two. Use the first passive approach to change investment option from aggressive to balanced to capital guaranteed with your life stages, however use the second active approach to time the change. For example, if you were say in your late 40s now and were looking to change from aggressive to balanced in the near future, you could wait until the ASX200 crosses below the 200 day SMA before making the change. This way you could capture the majority of the uptrend (which could go on for years) before changing from the high growth/aggressive option to the balanced option. If you where after more control over your superannuation assets another option open to you is to start a SMSF, however I would recommend having at least $300K to $400K in assets before starting a SMSF, or else the annual costs would be too high as a percentage of your total super assets.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sgUx0P_PTMn",
        "colab_type": "code",
        "outputId": "b80fbf14-1f5f-41b3-8263-711c06e97472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(tokenizer.encode(test).tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'is', 'it', 'wise', 'to', 'switch', 'investment', 'strategy', 'frequently', '?', '[SEP]', 'my', 'super', 'fund', 'and', 'i', 'would', 'say', 'many', 'other', 'funds', 'give', 'you', 'one', 'free', 'switch', 'of', 'strategies', 'per', 'year', '.', 'some', 'suggest', 'you', 'should', 'change', 'from', 'high', 'growth', 'option', 'to', 'a', 'more', 'balance', 'option', 'once', 'you', 'are', 'say', 'about', '10', 'to', '15', 'years', 'from', 'retirement', ',', 'and', 'then', 'change', 'to', 'a', 'more', 'capital', 'guaranteed', 'option', 'a', 'few', 'years', 'from', 'retirement', '.', 'this', 'is', 'a', 'more', 'passive', 'approach', 'and', 'has', 'benefits', 'as', 'well', 'as', 'disadvantages', '.', 'the', 'benefit', 'is', 'that', 'there', 'is', 'not', 'much', 'work', 'involved', ',', 'you', 'just', 'change', 'your', 'investment', 'option', 'based', 'on', 'your', 'life', 'stage', ',', '2', 'to', '3', 'times', 'during', 'your', 'lifetime', '.', 'this', 'allows', 'you', 'to', 'take', 'more', 'risk', 'when', 'you', 'are', 'young', 'to', 'aim', 'for', 'higher', 'returns', ',', 'take', 'a', 'balanced', 'approach', 'with', 'moderate', 'risk', 'and', 'returns', 'during', 'the', 'middle', 'part', 'of', 'your', 'working', 'life', ',', 'and', 'take', 'less', 'risk', 'with', 'lower', 'returns', '(', 'above', 'inflation', ')', 'during', 'the', 'latter', 'part', 'of', 'your', 'working', 'life', '.', 'a', 'possible', 'disadvantage', 'of', 'this', 'strategy', 'is', 'you', 'may', 'be', 'in', 'the', 'higher', 'risk', '/', 'higher', 'growth', 'option', 'during', 'a', 'market', 'correction', 'and', 'then', 'change', 'to', 'a', 'more', 'balanced', 'option', 'just', 'when', 'the', 'market', 'starts', 'to', 'pick', 'up', 'again', '.', 'so', 'your', 'funds', 'will', 'be', 'hit', 'with', 'large', 'losses', 'whilst', 'the', 'market', 'is', 'in', 'retreat', 'and', 'just', 'when', 'things', 'look', 'to', 'be', 'getting', 'better', 'you', 'change', 'to', 'a', 'more', 'balanced', 'portfolio', 'and', 'miss', 'out', 'on', 'the', 'big', 'gains', '.', 'a', 'second', 'more', 'active', 'approach', 'would', 'be', 'to', 'track', 'the', 'market', 'and', 'change', 'investment', 'option', 'as', 'the', 'market', 'changes', '.', 'one', 'approach', 'which', 'shouldn', \"'\", 't', 'take', 'much', 'time', 'is', 'to', 'track', 'the', 'index', 'such', 'as', 'the', 'asx200', '(', 'if', 'you', 'investment', 'option', 'is', 'mainly', 'invested', 'in', 'the', 'australian', 'stock', 'market', ')', 'with', 'a', '200', 'day', 'simple', 'moving', 'average', '(', 'sma', ')', '.', 'the', 'concept', 'is', 'that', 'if', 'the', 'index', 'crosses', 'above', 'the', '200', 'day', 'sma', 'the', 'market', 'is', 'bullish', 'and', 'if', 'it', 'crosses', 'below', 'it', 'is', 'bearish', '.', 'see', 'the', 'chart', 'below', ':', 'this', 'strategy', 'will', 'work', 'well', 'when', 'the', 'market', 'is', 'trending', 'up', 'or', 'down', 'but', 'not', 'very', 'well', 'when', 'the', 'market', 'is', 'going', 'sideways', ',', 'as', 'you', 'will', 'be', 'changing', 'from', 'aggressive', 'to', 'balanced', 'and', 'back', 'too', 'often', '.', 'possibly', 'a', 'more', 'appropriate', 'option', 'would', 'be', 'a', 'combination', 'of', 'the', 'two', '.', 'use', 'the', 'first', 'passive', 'approach', 'to', 'change', 'investment', 'option', 'from', 'aggressive', 'to', 'balanced', 'to', 'capital', 'guaranteed', 'with', 'your', 'life', 'stages', ',', 'however', 'use', 'the', 'second', 'active', 'approach', 'to', 'time', 'the', 'change', '.', 'for', 'example', ',', 'if', 'you', 'were', 'say', 'in', 'your', 'late', '40s', 'now', 'and', 'were', 'looking', 'to', 'change', 'from', 'aggressive', 'to', 'balanced', 'in', 'the', 'near', 'future', ',', 'you', 'could', 'wait', 'until', 'the', 'asx200', 'crosses', 'below', 'the', '200', 'day', 'sma', 'before', 'making', 'the', 'change', '.', 'this', 'way', 'you', 'could', 'capture', 'the', 'majority', 'of', 'the', 'uptrend', '(', 'which', 'could', 'go', 'on', 'for', 'years', ')', 'before', 'changing', 'from', 'the', 'high', 'growth', '/', 'aggressive', 'option', 'to', 'the', 'balanced', 'option', '.', 'if', 'you', 'where', 'after', 'more', 'control', 'over', 'your', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd1TxUgR7PvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(dataset, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtVVSQF78cTc",
        "colab_type": "code",
        "outputId": "7be7583d-d603-4525-c262-47b3dc15a399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(len(train))\n",
        "len(test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1708"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE-6jLXZ8kxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.to_csv(path+'bert-lm/train.txt',index=False,header=False, sep=\"\\t\", quoting=csv.QUOTE_NONE)\n",
        "test.to_csv(path+'bert-lm/eval.txt',index=False,header=False, sep=\"\\t\", quoting=csv.QUOTE_NONE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go4agYQv8sot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "train_path = os.path.join(\"/content/\" + path+'bert-lm/train.txt')\n",
        "eval_path = os.path.join(\"/content/\" + path+'bert-lm/eval.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tsBmRyr-WAS",
        "colab_type": "code",
        "outputId": "67e6ad5b-3e32-4da2-af16-219b08f43023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 99, done.\u001b[K\n",
            "remote: Counting objects: 100% (99/99), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 20817 (delta 56), reused 82 (delta 47), pack-reused 20718\u001b[K\n",
            "Receiving objects: 100% (20817/20817), 12.34 MiB | 26.93 MiB/s, done.\n",
            "Resolving deltas: 100% (15040/15040), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rsayGXzCID_",
        "colab_type": "code",
        "outputId": "be1c3112-6070-4437-e63d-9ae7f34972fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Feb 28 11:39:11 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8     7W /  75W |     10MiB /  7611MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuLEQKEs-eGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "#Setting environment variables\n",
        "os.environ[\"train_path\"] = train_path\n",
        "os.environ[\"eval_path\"] = eval_path\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"]='1'  #Makes for easier debugging (just in case)\n",
        "weights_dir = \"/content/drive/'My Drive'/FiQA/bert-lm/weights\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI9OGeYoBXu1",
        "colab_type": "code",
        "outputId": "6f95c59f-6345-4d3c-9010-1f02d5871750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "weights_dir"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"/content/drive/'My Drive'/FiQA/bert-lm/weights\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_qbLdLT_Iz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cmd = '''python /content/transformers/examples/run_language_modeling.py \\\n",
        "    --output_dir /content/drive/'My Drive'/FiQA/bert-lm/weights \\\n",
        "    --model_type bert \\\n",
        "    --mlm \\\n",
        "    --train_data_file /content/drive/'My Drive'/FiQA/bert-lm/train.txt \\\n",
        "    --eval_data_file /content/drive/'My Drive'/FiQA/bert-lm/eval.txt \\\n",
        "    --config_name /content/drive/'My Drive'/FiQA/bert-lm/tokenizer \\\n",
        "    --tokenizer_name /content/drive/'My Drive'/FiQA/bert-lm/tokenizer \\\n",
        "    --do_train \\\n",
        "    --line_by_line \\\n",
        "    --overwrite_output_dir \\\n",
        "    --do_eval \\\n",
        "    --learning_rate 1e-4 \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --save_total_limit 2 \\\n",
        "    --block_size 512 \\\n",
        "    --save_steps 2000 \\\n",
        "    --per_gpu_eval_batch_size 8 \\\n",
        "    --per_gpu_train_batch_size 8 \\\n",
        "    --evaluate_during_training \\\n",
        "    --seed 42'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-wUC508_88k",
        "colab_type": "code",
        "outputId": "806feac4-61e4-43d4-e0e2-d7a4d1fe7614",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!{cmd}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "02/28/2020 11:39:34 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "02/28/2020 11:39:34 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/My Drive/FiQA/bert-lm/tokenizer/config.json\n",
            "02/28/2020 11:39:34 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 28989\n",
            "}\n",
            "\n",
            "02/28/2020 11:39:34 - INFO - transformers.tokenization_utils -   Model name '/content/drive/My Drive/FiQA/bert-lm/tokenizer' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming '/content/drive/My Drive/FiQA/bert-lm/tokenizer' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "02/28/2020 11:39:34 - INFO - transformers.tokenization_utils -   Didn't find file /content/drive/My Drive/FiQA/bert-lm/tokenizer/added_tokens.json. We won't load it.\n",
            "02/28/2020 11:39:34 - INFO - transformers.tokenization_utils -   Didn't find file /content/drive/My Drive/FiQA/bert-lm/tokenizer/special_tokens_map.json. We won't load it.\n",
            "02/28/2020 11:39:34 - INFO - transformers.tokenization_utils -   Didn't find file /content/drive/My Drive/FiQA/bert-lm/tokenizer/tokenizer_config.json. We won't load it.\n",
            "02/28/2020 11:39:34 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/FiQA/bert-lm/tokenizer/vocab.txt\n",
            "02/28/2020 11:39:34 - INFO - transformers.tokenization_utils -   loading file None\n",
            "02/28/2020 11:39:34 - INFO - transformers.tokenization_utils -   loading file None\n",
            "02/28/2020 11:39:34 - INFO - transformers.tokenization_utils -   loading file None\n",
            "02/28/2020 11:39:35 - INFO - __main__ -   Training new model from scratch\n",
            "02/28/2020 11:39:47 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name='/content/drive/My Drive/FiQA/bert-lm/tokenizer', device=device(type='cuda'), do_eval=True, do_train=True, eval_all_checkpoints=False, eval_data_file='/content/drive/My Drive/FiQA/bert-lm/eval.txt', evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=0.0001, line_by_line=True, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path=None, model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='/content/drive/My Drive/FiQA/bert-lm/weights', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, save_steps=2000, save_total_limit=2, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name='/content/drive/My Drive/FiQA/bert-lm/tokenizer', train_data_file='/content/drive/My Drive/FiQA/bert-lm/train.txt', warmup_steps=0, weight_decay=0.0)\n",
            "02/28/2020 11:39:47 - INFO - __main__ -   Creating features from dataset file at /content/drive/My Drive/FiQA/bert-lm/train.txt\n",
            "02/28/2020 11:40:34 - INFO - __main__ -   ***** Running training *****\n",
            "02/28/2020 11:40:34 - INFO - __main__ -     Num examples = 15364\n",
            "02/28/2020 11:40:34 - INFO - __main__ -     Num Epochs = 1\n",
            "02/28/2020 11:40:34 - INFO - __main__ -     Instantaneous batch size per GPU = 8\n",
            "02/28/2020 11:40:34 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "02/28/2020 11:40:34 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "02/28/2020 11:40:34 - INFO - __main__ -     Total optimization steps = 1921\n",
            "Epoch:   0% 0/1 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/1921 [00:00<?, ?it/s]\u001b[ATraceback (most recent call last):\n",
            "  File \"/content/transformers/examples/run_language_modeling.py\", line 799, in <module>\n",
            "    main()\n",
            "  File \"/content/transformers/examples/run_language_modeling.py\", line 749, in main\n",
            "    global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n",
            "  File \"/content/transformers/examples/run_language_modeling.py\", line 353, in train\n",
            "    outputs = model(inputs, masked_lm_labels=labels) if args.mlm else model(inputs, labels=labels)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\", line 1003, in forward\n",
            "    masked_lm_loss = loss_fct(prediction_scores.view(-1, self.config.vocab_size), masked_lm_labels.view(-1))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\", line 916, in forward\n",
            "    ignore_index=self.ignore_index, reduction=self.reduction)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\", line 2021, in cross_entropy\n",
            "    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\", line 1317, in log_softmax\n",
            "    ret = input.log_softmax(dim)\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 434.00 MiB (GPU 0; 7.43 GiB total capacity; 6.52 GiB already allocated; 366.94 MiB free; 6.55 GiB reserved in total by PyTorch)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QX2QHXO1JyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}